{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multicollinearity Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result we got in the modeling process was disappointing; the performance reflected on the R-square score was low, and it is not proper to be brought forward to the production phase.\n",
    "\n",
    "So we will try to evaluate the dataset to get a better result.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libaries and Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "df = pd.read_csv('/home/er_bim/productivity-prediction/notebooks/data/worker_productivity_processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Retraining with Features Reduction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5642e_row0_col0, #T_5642e_row1_col1, #T_5642e_row2_col2, #T_5642e_row3_col3, #T_5642e_row4_col4, #T_5642e_row5_col5, #T_5642e_row6_col6, #T_5642e_row7_col7, #T_5642e_row8_col8 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5642e_row0_col1, #T_5642e_row2_col3 {\n",
       "  background-color: #8badfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5642e_row0_col2 {\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5642e_row0_col3, #T_5642e_row7_col1 {\n",
       "  background-color: #5977e3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5642e_row0_col4, #T_5642e_row0_col5, #T_5642e_row1_col3, #T_5642e_row1_col6, #T_5642e_row1_col7, #T_5642e_row4_col0, #T_5642e_row6_col1, #T_5642e_row6_col8, #T_5642e_row8_col2 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5642e_row0_col6, #T_5642e_row1_col0, #T_5642e_row3_col6 {\n",
       "  background-color: #7093f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5642e_row0_col7, #T_5642e_row1_col4, #T_5642e_row8_col6 {\n",
       "  background-color: #455cce;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5642e_row0_col8 {\n",
       "  background-color: #4f69d9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5642e_row1_col2, #T_5642e_row2_col0 {\n",
       "  background-color: #3e51c5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5642e_row1_col5 {\n",
       "  background-color: #7295f4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5642e_row1_col8 {\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5642e_row2_col1 {\n",
       "  background-color: #5b7ae5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5642e_row2_col4, #T_5642e_row4_col2 {\n",
       "  background-color: #f6a586;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5642e_row2_col5 {\n",
       "  background-color: #f4c6af;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5642e_row2_col6, #T_5642e_row7_col6 {\n",
       "  background-color: #cdd9ec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5642e_row2_col7, #T_5642e_row7_col2 {\n",
       "  background-color: #d24b40;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5642e_row2_col8 {\n",
       "  background-color: #4b64d5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5642e_row3_col0, #T_5642e_row4_col1 {\n",
       "  background-color: #6180e9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5642e_row3_col1 {\n",
       "  background-color: #5d7ce6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5642e_row3_col2, #T_5642e_row8_col5 {\n",
       "  background-color: #90b2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5642e_row3_col4 {\n",
       "  background-color: #c4d5f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5642e_row3_col5 {\n",
       "  background-color: #b2ccfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5642e_row3_col7 {\n",
       "  background-color: #aec9fc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5642e_row3_col8 {\n",
       "  background-color: #82a6fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5642e_row4_col3 {\n",
       "  background-color: #bfd3f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5642e_row4_col5 {\n",
       "  background-color: #efcfbf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5642e_row4_col6 {\n",
       "  background-color: #86a9fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5642e_row4_col7 {\n",
       "  background-color: #f18f71;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5642e_row4_col8 {\n",
       "  background-color: #6687ed;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5642e_row5_col0 {\n",
       "  background-color: #5e7de7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5642e_row5_col1 {\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5642e_row5_col2 {\n",
       "  background-color: #f7b99e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5642e_row5_col3 {\n",
       "  background-color: #c5d6f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5642e_row5_col4 {\n",
       "  background-color: #f5c4ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5642e_row5_col6 {\n",
       "  background-color: #80a3fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5642e_row5_col7 {\n",
       "  background-color: #f39778;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5642e_row5_col8, #T_5642e_row6_col7 {\n",
       "  background-color: #bad0f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5642e_row6_col0 {\n",
       "  background-color: #5572df;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5642e_row6_col2 {\n",
       "  background-color: #bbd1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5642e_row6_col3 {\n",
       "  background-color: #4c66d6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5642e_row6_col4, #T_5642e_row8_col3 {\n",
       "  background-color: #6b8df0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5642e_row6_col5 {\n",
       "  background-color: #4055c8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5642e_row7_col0 {\n",
       "  background-color: #485fd1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5642e_row7_col3 {\n",
       "  background-color: #abc8fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5642e_row7_col4 {\n",
       "  background-color: #f18d6f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5642e_row7_col5 {\n",
       "  background-color: #f6a385;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5642e_row7_col8 {\n",
       "  background-color: #6485ec;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5642e_row8_col0 {\n",
       "  background-color: #3f53c6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5642e_row8_col1 {\n",
       "  background-color: #e2dad5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5642e_row8_col4 {\n",
       "  background-color: #5673e0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5642e_row8_col7 {\n",
       "  background-color: #516ddb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5642e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5642e_level0_col0\" class=\"col_heading level0 col0\" >team</th>\n",
       "      <th id=\"T_5642e_level0_col1\" class=\"col_heading level0 col1\" >targeted_productivity</th>\n",
       "      <th id=\"T_5642e_level0_col2\" class=\"col_heading level0 col2\" >smv</th>\n",
       "      <th id=\"T_5642e_level0_col3\" class=\"col_heading level0 col3\" >wip</th>\n",
       "      <th id=\"T_5642e_level0_col4\" class=\"col_heading level0 col4\" >over_time</th>\n",
       "      <th id=\"T_5642e_level0_col5\" class=\"col_heading level0 col5\" >incentive</th>\n",
       "      <th id=\"T_5642e_level0_col6\" class=\"col_heading level0 col6\" >no_of_style_change</th>\n",
       "      <th id=\"T_5642e_level0_col7\" class=\"col_heading level0 col7\" >no_of_workers</th>\n",
       "      <th id=\"T_5642e_level0_col8\" class=\"col_heading level0 col8\" >actual_productivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5642e_level0_row0\" class=\"row_heading level0 row0\" >team</th>\n",
       "      <td id=\"T_5642e_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "      <td id=\"T_5642e_row0_col1\" class=\"data row0 col1\" >0.073000</td>\n",
       "      <td id=\"T_5642e_row0_col2\" class=\"data row0 col2\" >-0.103000</td>\n",
       "      <td id=\"T_5642e_row0_col3\" class=\"data row0 col3\" >0.021000</td>\n",
       "      <td id=\"T_5642e_row0_col4\" class=\"data row0 col4\" >-0.117000</td>\n",
       "      <td id=\"T_5642e_row0_col5\" class=\"data row0 col5\" >0.013000</td>\n",
       "      <td id=\"T_5642e_row0_col6\" class=\"data row0 col6\" >-0.018000</td>\n",
       "      <td id=\"T_5642e_row0_col7\" class=\"data row0 col7\" >-0.065000</td>\n",
       "      <td id=\"T_5642e_row0_col8\" class=\"data row0 col8\" >-0.099000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5642e_level0_row1\" class=\"row_heading level0 row1\" >targeted_productivity</th>\n",
       "      <td id=\"T_5642e_row1_col0\" class=\"data row1 col0\" >0.073000</td>\n",
       "      <td id=\"T_5642e_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "      <td id=\"T_5642e_row1_col2\" class=\"data row1 col2\" >-0.096000</td>\n",
       "      <td id=\"T_5642e_row1_col3\" class=\"data row1 col3\" >-0.088000</td>\n",
       "      <td id=\"T_5642e_row1_col4\" class=\"data row1 col4\" >-0.076000</td>\n",
       "      <td id=\"T_5642e_row1_col5\" class=\"data row1 col5\" >0.183000</td>\n",
       "      <td id=\"T_5642e_row1_col6\" class=\"data row1 col6\" >-0.226000</td>\n",
       "      <td id=\"T_5642e_row1_col7\" class=\"data row1 col7\" >-0.104000</td>\n",
       "      <td id=\"T_5642e_row1_col8\" class=\"data row1 col8\" >0.411000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5642e_level0_row2\" class=\"row_heading level0 row2\" >smv</th>\n",
       "      <td id=\"T_5642e_row2_col0\" class=\"data row2 col0\" >-0.103000</td>\n",
       "      <td id=\"T_5642e_row2_col1\" class=\"data row2 col1\" >-0.096000</td>\n",
       "      <td id=\"T_5642e_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "      <td id=\"T_5642e_row2_col3\" class=\"data row2 col3\" >0.177000</td>\n",
       "      <td id=\"T_5642e_row2_col4\" class=\"data row2 col4\" >0.689000</td>\n",
       "      <td id=\"T_5642e_row2_col5\" class=\"data row2 col5\" >0.624000</td>\n",
       "      <td id=\"T_5642e_row2_col6\" class=\"data row2 col6\" >0.317000</td>\n",
       "      <td id=\"T_5642e_row2_col7\" class=\"data row2 col7\" >0.901000</td>\n",
       "      <td id=\"T_5642e_row2_col8\" class=\"data row2 col8\" >-0.112000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5642e_level0_row3\" class=\"row_heading level0 row3\" >wip</th>\n",
       "      <td id=\"T_5642e_row3_col0\" class=\"data row3 col0\" >0.021000</td>\n",
       "      <td id=\"T_5642e_row3_col1\" class=\"data row3 col1\" >-0.088000</td>\n",
       "      <td id=\"T_5642e_row3_col2\" class=\"data row3 col2\" >0.177000</td>\n",
       "      <td id=\"T_5642e_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "      <td id=\"T_5642e_row3_col4\" class=\"data row3 col4\" >0.344000</td>\n",
       "      <td id=\"T_5642e_row3_col5\" class=\"data row3 col5\" >0.365000</td>\n",
       "      <td id=\"T_5642e_row3_col6\" class=\"data row3 col6\" >-0.020000</td>\n",
       "      <td id=\"T_5642e_row3_col7\" class=\"data row3 col7\" >0.278000</td>\n",
       "      <td id=\"T_5642e_row3_col8\" class=\"data row3 col8\" >0.082000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5642e_level0_row4\" class=\"row_heading level0 row4\" >over_time</th>\n",
       "      <td id=\"T_5642e_row4_col0\" class=\"data row4 col0\" >-0.117000</td>\n",
       "      <td id=\"T_5642e_row4_col1\" class=\"data row4 col1\" >-0.076000</td>\n",
       "      <td id=\"T_5642e_row4_col2\" class=\"data row4 col2\" >0.689000</td>\n",
       "      <td id=\"T_5642e_row4_col3\" class=\"data row4 col3\" >0.344000</td>\n",
       "      <td id=\"T_5642e_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "      <td id=\"T_5642e_row4_col5\" class=\"data row4 col5\" >0.584000</td>\n",
       "      <td id=\"T_5642e_row4_col6\" class=\"data row4 col6\" >0.057000</td>\n",
       "      <td id=\"T_5642e_row4_col7\" class=\"data row4 col7\" >0.754000</td>\n",
       "      <td id=\"T_5642e_row4_col8\" class=\"data row4 col8\" >-0.014000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5642e_level0_row5\" class=\"row_heading level0 row5\" >incentive</th>\n",
       "      <td id=\"T_5642e_row5_col0\" class=\"data row5 col0\" >0.013000</td>\n",
       "      <td id=\"T_5642e_row5_col1\" class=\"data row5 col1\" >0.183000</td>\n",
       "      <td id=\"T_5642e_row5_col2\" class=\"data row5 col2\" >0.624000</td>\n",
       "      <td id=\"T_5642e_row5_col3\" class=\"data row5 col3\" >0.365000</td>\n",
       "      <td id=\"T_5642e_row5_col4\" class=\"data row5 col4\" >0.584000</td>\n",
       "      <td id=\"T_5642e_row5_col5\" class=\"data row5 col5\" >1.000000</td>\n",
       "      <td id=\"T_5642e_row5_col6\" class=\"data row5 col6\" >0.036000</td>\n",
       "      <td id=\"T_5642e_row5_col7\" class=\"data row5 col7\" >0.729000</td>\n",
       "      <td id=\"T_5642e_row5_col8\" class=\"data row5 col8\" >0.271000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5642e_level0_row6\" class=\"row_heading level0 row6\" >no_of_style_change</th>\n",
       "      <td id=\"T_5642e_row6_col0\" class=\"data row6 col0\" >-0.018000</td>\n",
       "      <td id=\"T_5642e_row6_col1\" class=\"data row6 col1\" >-0.226000</td>\n",
       "      <td id=\"T_5642e_row6_col2\" class=\"data row6 col2\" >0.317000</td>\n",
       "      <td id=\"T_5642e_row6_col3\" class=\"data row6 col3\" >-0.020000</td>\n",
       "      <td id=\"T_5642e_row6_col4\" class=\"data row6 col4\" >0.057000</td>\n",
       "      <td id=\"T_5642e_row6_col5\" class=\"data row6 col5\" >0.036000</td>\n",
       "      <td id=\"T_5642e_row6_col6\" class=\"data row6 col6\" >1.000000</td>\n",
       "      <td id=\"T_5642e_row6_col7\" class=\"data row6 col7\" >0.317000</td>\n",
       "      <td id=\"T_5642e_row6_col8\" class=\"data row6 col8\" >-0.179000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5642e_level0_row7\" class=\"row_heading level0 row7\" >no_of_workers</th>\n",
       "      <td id=\"T_5642e_row7_col0\" class=\"data row7 col0\" >-0.065000</td>\n",
       "      <td id=\"T_5642e_row7_col1\" class=\"data row7 col1\" >-0.104000</td>\n",
       "      <td id=\"T_5642e_row7_col2\" class=\"data row7 col2\" >0.901000</td>\n",
       "      <td id=\"T_5642e_row7_col3\" class=\"data row7 col3\" >0.278000</td>\n",
       "      <td id=\"T_5642e_row7_col4\" class=\"data row7 col4\" >0.754000</td>\n",
       "      <td id=\"T_5642e_row7_col5\" class=\"data row7 col5\" >0.729000</td>\n",
       "      <td id=\"T_5642e_row7_col6\" class=\"data row7 col6\" >0.317000</td>\n",
       "      <td id=\"T_5642e_row7_col7\" class=\"data row7 col7\" >1.000000</td>\n",
       "      <td id=\"T_5642e_row7_col8\" class=\"data row7 col8\" >-0.022000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5642e_level0_row8\" class=\"row_heading level0 row8\" >actual_productivity</th>\n",
       "      <td id=\"T_5642e_row8_col0\" class=\"data row8 col0\" >-0.099000</td>\n",
       "      <td id=\"T_5642e_row8_col1\" class=\"data row8 col1\" >0.411000</td>\n",
       "      <td id=\"T_5642e_row8_col2\" class=\"data row8 col2\" >-0.112000</td>\n",
       "      <td id=\"T_5642e_row8_col3\" class=\"data row8 col3\" >0.082000</td>\n",
       "      <td id=\"T_5642e_row8_col4\" class=\"data row8 col4\" >-0.014000</td>\n",
       "      <td id=\"T_5642e_row8_col5\" class=\"data row8 col5\" >0.271000</td>\n",
       "      <td id=\"T_5642e_row8_col6\" class=\"data row8 col6\" >-0.179000</td>\n",
       "      <td id=\"T_5642e_row8_col7\" class=\"data row8 col7\" >-0.022000</td>\n",
       "      <td id=\"T_5642e_row8_col8\" class=\"data row8 col8\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fc79c2065f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the correlation matrix\n",
    "corr = df.corr(numeric_only=True).round(3)\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some predictors that highly-correlated between them, thus indicates the multicollinearity.\n",
    "\n",
    "Let's check their Variance Influence Factor (VIF) value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>146.486641</td>\n",
       "      <td>Intercept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.235793</td>\n",
       "      <td>targeted_productivity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.538228</td>\n",
       "      <td>smv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.272798</td>\n",
       "      <td>wip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.660465</td>\n",
       "      <td>over_time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.875632</td>\n",
       "      <td>incentive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.351204</td>\n",
       "      <td>no_of_style_change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.014431</td>\n",
       "      <td>no_of_workers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          VIF               features\n",
       "0  146.486641              Intercept\n",
       "1    1.235793  targeted_productivity\n",
       "2    5.538228                    smv\n",
       "3    1.272798                    wip\n",
       "4    2.660465              over_time\n",
       "5    2.875632              incentive\n",
       "6    1.351204     no_of_style_change\n",
       "7    9.014431          no_of_workers"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the libraries\n",
    "from patsy import dmatrices\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# run the VIF calculation on df, with column 'actual_productivity' as target\n",
    "y, X = dmatrices('actual_productivity ~ targeted_productivity+smv+wip+over_time+incentive+no_of_style_change+no_of_workers',\n",
    "                 data=df, return_type='dataframe')\n",
    "\n",
    "# create the report tabel\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif[\"features\"] = X.columns\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two features that have VIF more than 5, which number indicates the feature caused multicollinearity in the dataset.\n",
    "\n",
    "Let's try to exclude column `no_of workers` first and recalculate the VIF values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140.963010</td>\n",
       "      <td>Intercept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.202568</td>\n",
       "      <td>targeted_productivity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.814492</td>\n",
       "      <td>smv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.272108</td>\n",
       "      <td>wip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.286510</td>\n",
       "      <td>over_time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.213751</td>\n",
       "      <td>incentive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.246215</td>\n",
       "      <td>no_of_style_change</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          VIF               features\n",
       "0  140.963010              Intercept\n",
       "1    1.202568  targeted_productivity\n",
       "2    2.814492                    smv\n",
       "3    1.272108                    wip\n",
       "4    2.286510              over_time\n",
       "5    2.213751              incentive\n",
       "6    1.246215     no_of_style_change"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the VIF calculation on df, with column 'actual_productivity' as target and column 'no_of workers' excluded\n",
    "y, X = dmatrices('actual_productivity ~ targeted_productivity+smv+wip+over_time+incentive+no_of_style_change',\n",
    "                 data=df, return_type='dataframe')\n",
    "\n",
    "# create the report tabel\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif[\"features\"] = X.columns\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result shows that there are still some features valued more than two, that means those features is moderately-correlated at least with one other feature.\n",
    "\n",
    "Let's recheck the correlation matrix after the columns with VIF value >2 are dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ce55c_row0_col0, #T_ce55c_row1_col1, #T_ce55c_row2_col2, #T_ce55c_row3_col3, #T_ce55c_row4_col4, #T_ce55c_row5_col5 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ce55c_row0_col1 {\n",
       "  background-color: #8badfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ce55c_row0_col2 {\n",
       "  background-color: #5977e3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ce55c_row0_col3, #T_ce55c_row1_col2, #T_ce55c_row1_col4, #T_ce55c_row3_col0, #T_ce55c_row4_col1, #T_ce55c_row4_col5 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ce55c_row0_col4, #T_ce55c_row1_col0, #T_ce55c_row2_col4 {\n",
       "  background-color: #7093f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ce55c_row0_col5 {\n",
       "  background-color: #4f69d9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ce55c_row1_col3, #T_ce55c_row5_col4 {\n",
       "  background-color: #455cce;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ce55c_row1_col5 {\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ce55c_row2_col0, #T_ce55c_row3_col1 {\n",
       "  background-color: #6180e9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ce55c_row2_col1 {\n",
       "  background-color: #5d7ce6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ce55c_row2_col3 {\n",
       "  background-color: #c4d5f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ce55c_row2_col5 {\n",
       "  background-color: #82a6fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ce55c_row3_col2 {\n",
       "  background-color: #bfd3f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ce55c_row3_col4 {\n",
       "  background-color: #86a9fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ce55c_row3_col5 {\n",
       "  background-color: #6687ed;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ce55c_row4_col0 {\n",
       "  background-color: #5572df;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ce55c_row4_col2 {\n",
       "  background-color: #4c66d6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ce55c_row4_col3, #T_ce55c_row5_col2 {\n",
       "  background-color: #6b8df0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ce55c_row5_col0 {\n",
       "  background-color: #3f53c6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_ce55c_row5_col1 {\n",
       "  background-color: #e2dad5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_ce55c_row5_col3 {\n",
       "  background-color: #5673e0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ce55c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ce55c_level0_col0\" class=\"col_heading level0 col0\" >team</th>\n",
       "      <th id=\"T_ce55c_level0_col1\" class=\"col_heading level0 col1\" >targeted_productivity</th>\n",
       "      <th id=\"T_ce55c_level0_col2\" class=\"col_heading level0 col2\" >wip</th>\n",
       "      <th id=\"T_ce55c_level0_col3\" class=\"col_heading level0 col3\" >over_time</th>\n",
       "      <th id=\"T_ce55c_level0_col4\" class=\"col_heading level0 col4\" >no_of_style_change</th>\n",
       "      <th id=\"T_ce55c_level0_col5\" class=\"col_heading level0 col5\" >actual_productivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ce55c_level0_row0\" class=\"row_heading level0 row0\" >team</th>\n",
       "      <td id=\"T_ce55c_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "      <td id=\"T_ce55c_row0_col1\" class=\"data row0 col1\" >0.073000</td>\n",
       "      <td id=\"T_ce55c_row0_col2\" class=\"data row0 col2\" >0.021000</td>\n",
       "      <td id=\"T_ce55c_row0_col3\" class=\"data row0 col3\" >-0.117000</td>\n",
       "      <td id=\"T_ce55c_row0_col4\" class=\"data row0 col4\" >-0.018000</td>\n",
       "      <td id=\"T_ce55c_row0_col5\" class=\"data row0 col5\" >-0.099000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ce55c_level0_row1\" class=\"row_heading level0 row1\" >targeted_productivity</th>\n",
       "      <td id=\"T_ce55c_row1_col0\" class=\"data row1 col0\" >0.073000</td>\n",
       "      <td id=\"T_ce55c_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "      <td id=\"T_ce55c_row1_col2\" class=\"data row1 col2\" >-0.088000</td>\n",
       "      <td id=\"T_ce55c_row1_col3\" class=\"data row1 col3\" >-0.076000</td>\n",
       "      <td id=\"T_ce55c_row1_col4\" class=\"data row1 col4\" >-0.226000</td>\n",
       "      <td id=\"T_ce55c_row1_col5\" class=\"data row1 col5\" >0.411000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ce55c_level0_row2\" class=\"row_heading level0 row2\" >wip</th>\n",
       "      <td id=\"T_ce55c_row2_col0\" class=\"data row2 col0\" >0.021000</td>\n",
       "      <td id=\"T_ce55c_row2_col1\" class=\"data row2 col1\" >-0.088000</td>\n",
       "      <td id=\"T_ce55c_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "      <td id=\"T_ce55c_row2_col3\" class=\"data row2 col3\" >0.344000</td>\n",
       "      <td id=\"T_ce55c_row2_col4\" class=\"data row2 col4\" >-0.020000</td>\n",
       "      <td id=\"T_ce55c_row2_col5\" class=\"data row2 col5\" >0.082000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ce55c_level0_row3\" class=\"row_heading level0 row3\" >over_time</th>\n",
       "      <td id=\"T_ce55c_row3_col0\" class=\"data row3 col0\" >-0.117000</td>\n",
       "      <td id=\"T_ce55c_row3_col1\" class=\"data row3 col1\" >-0.076000</td>\n",
       "      <td id=\"T_ce55c_row3_col2\" class=\"data row3 col2\" >0.344000</td>\n",
       "      <td id=\"T_ce55c_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "      <td id=\"T_ce55c_row3_col4\" class=\"data row3 col4\" >0.057000</td>\n",
       "      <td id=\"T_ce55c_row3_col5\" class=\"data row3 col5\" >-0.014000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ce55c_level0_row4\" class=\"row_heading level0 row4\" >no_of_style_change</th>\n",
       "      <td id=\"T_ce55c_row4_col0\" class=\"data row4 col0\" >-0.018000</td>\n",
       "      <td id=\"T_ce55c_row4_col1\" class=\"data row4 col1\" >-0.226000</td>\n",
       "      <td id=\"T_ce55c_row4_col2\" class=\"data row4 col2\" >-0.020000</td>\n",
       "      <td id=\"T_ce55c_row4_col3\" class=\"data row4 col3\" >0.057000</td>\n",
       "      <td id=\"T_ce55c_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "      <td id=\"T_ce55c_row4_col5\" class=\"data row4 col5\" >-0.179000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ce55c_level0_row5\" class=\"row_heading level0 row5\" >actual_productivity</th>\n",
       "      <td id=\"T_ce55c_row5_col0\" class=\"data row5 col0\" >-0.099000</td>\n",
       "      <td id=\"T_ce55c_row5_col1\" class=\"data row5 col1\" >0.411000</td>\n",
       "      <td id=\"T_ce55c_row5_col2\" class=\"data row5 col2\" >0.082000</td>\n",
       "      <td id=\"T_ce55c_row5_col3\" class=\"data row5 col3\" >-0.014000</td>\n",
       "      <td id=\"T_ce55c_row5_col4\" class=\"data row5 col4\" >-0.179000</td>\n",
       "      <td id=\"T_ce55c_row5_col5\" class=\"data row5 col5\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fc764ce3e50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the column \"no_of_workers\"\n",
    "df.drop(columns=['no_of_workers', 'smv', 'incentive'], inplace=True)\n",
    "\n",
    "# print the correlation matrix\n",
    "corr = df.corr(numeric_only=True).round(3)\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression, Ridge,Lasso\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Dataset for Modelling Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate the predictors and target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we separate the features in the dataset as predictors and target.\n",
    "\n",
    "The target (y variable) feature is `actual_producticity`, thus the rest of the of the features after the feature `date` is eliminated are the predictors (X variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predictors consist of 8 columns and 1108 rows.\n",
      "\n",
      "The target column is actual_productivity which consist of 1108 rows.\n"
     ]
    }
   ],
   "source": [
    "# set the X variables\n",
    "X = df.drop(columns=['date', 'actual_productivity'],axis=1)\n",
    "\n",
    "# set the y variable\n",
    "y = df['actual_productivity']\n",
    "\n",
    "# recheck the shape of each variable\n",
    "print(f\"The predictors consist of {X.shape[1]} columns and {X.shape[0]} rows.\\n\" )\n",
    "print(f\"The target column is {y.name} which consist of {y.shape[0]} rows.\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>department</th>\n",
       "      <th>day</th>\n",
       "      <th>team</th>\n",
       "      <th>targeted_productivity</th>\n",
       "      <th>wip</th>\n",
       "      <th>over_time</th>\n",
       "      <th>no_of_style_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Week1</td>\n",
       "      <td>sewing</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1108</td>\n",
       "      <td>7080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Week1</td>\n",
       "      <td>finishing</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>802</td>\n",
       "      <td>960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Week1</td>\n",
       "      <td>sewing</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>11</td>\n",
       "      <td>0.80</td>\n",
       "      <td>968</td>\n",
       "      <td>3660</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    week department       day  team  targeted_productivity   wip  over_time  \\\n",
       "0  Week1     sewing  Thursday     8                   0.80  1108       7080   \n",
       "1  Week1  finishing  Thursday     1                   0.75   802        960   \n",
       "2  Week1     sewing  Thursday    11                   0.80   968       3660   \n",
       "\n",
       "   no_of_style_change  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recheck the predictors\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.940725\n",
       "1    0.886500\n",
       "2    0.800570\n",
       "Name: actual_productivity, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recheck the target column\n",
    "y.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Dataset into Train and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will split the dataset into 70% train and 30% test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the predictors value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categorical features need to be encoded to fit the model training; I chose the one-hot encoding method for this dataset.\n",
    "\n",
    "For the numerical features, I want to do the experiment that both will be trained; the first one will be trained as the original value, and the second will be transformed first to make the value compacted. I choose the robust scaler transformation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create instance for numerical and categorical features\n",
    "num = X._get_numeric_data().columns\n",
    "cat = X.drop(num, axis = 1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libaries for column transformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "rob_scaler = RobustScaler()\n",
    "cat_encoder = OneHotEncoder()\n",
    "\n",
    "# create column transformer pipeline for original value numerical features\n",
    "preprocessor1 = ColumnTransformer([(\"OneHotEncoder\", cat_encoder, cat), \n",
    "                                  (\"passthrough\", \"passthrough\", num)]\n",
    "                                )\n",
    "\n",
    "# create column transformer pipeline for standard scaled numerical features\n",
    "preprocessor2 = ColumnTransformer([(\"OneHotEncoder\", cat_encoder, cat), \n",
    "                                  (\"StandardScaler\", std_scaler, num)]\n",
    "                                )\n",
    "\n",
    "# create column transformer pipeline for robust scaled numerical features\n",
    "preprocessor3 = ColumnTransformer([(\"OneHotEncoder\", cat_encoder, cat), \n",
    "                                  (\"RobustScaler\", rob_scaler, num)]\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and transform X_train with original value in numerical features\n",
    "X_train_ori = preprocessor1.fit_transform(X_train)\n",
    "\n",
    "# transform X_test with original value in numerical features\n",
    "X_test_ori = preprocessor1.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and transform X_train with original value in numerical features\n",
    "X_train_std_scaled = preprocessor2.fit_transform(X_train)\n",
    "\n",
    "# transform X_test with original value in numerical features\n",
    "X_test_std_scaled = preprocessor2.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and transform X_train with original value in numerical features\n",
    "X_train_rob_scaled = preprocessor3.fit_transform(X_train)\n",
    "\n",
    "# transform X_test with original value in numerical features\n",
    "X_test_rob_scaled = preprocessor2.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try to do the modelling process of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the function for model evaluation \n",
    "def evaluate_model(true, predicted):\n",
    "    mae = mean_absolute_error(true, predicted)\n",
    "    mse = mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(true, predicted))\n",
    "    r2_square = r2_score(true, predicted)\n",
    "    return mae, rmse, r2_square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Value Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1381\n",
      "- Mean Absolute Error: 0.0969\n",
      "- R2 Score: 0.2355\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1563\n",
      "- Mean Absolute Error: 0.1103\n",
      "- R2 Score: 0.2034\n",
      "===================================\n",
      "\n",
      "\n",
      "Lasso\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1573\n",
      "- Mean Absolute Error: 0.1228\n",
      "- R2 Score: 0.0084\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1754\n",
      "- Mean Absolute Error: 0.1333\n",
      "- R2 Score: -0.0027\n",
      "===================================\n",
      "\n",
      "\n",
      "Ridge\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1386\n",
      "- Mean Absolute Error: 0.0993\n",
      "- R2 Score: 0.2296\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1576\n",
      "- Mean Absolute Error: 0.1127\n",
      "- R2 Score: 0.1910\n",
      "===================================\n",
      "\n",
      "\n",
      "SVR\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1556\n",
      "- Mean Absolute Error: 0.1206\n",
      "- R2 Score: 0.0291\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1785\n",
      "- Mean Absolute Error: 0.1336\n",
      "- R2 Score: -0.0384\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1234\n",
      "- Mean Absolute Error: 0.0896\n",
      "- R2 Score: 0.3893\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1727\n",
      "- Mean Absolute Error: 0.1248\n",
      "- R2 Score: 0.0277\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.2004\n",
      "- Mean Absolute Error: 0.1266\n",
      "- R2 Score: -0.3082\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0493\n",
      "- Mean Absolute Error: 0.0330\n",
      "- R2 Score: 0.9025\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1438\n",
      "- Mean Absolute Error: 0.0978\n",
      "- R2 Score: 0.3262\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBRegressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0127\n",
      "- Mean Absolute Error: 0.0080\n",
      "- R2 Score: 0.9936\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1468\n",
      "- Mean Absolute Error: 0.1008\n",
      "- R2 Score: 0.2981\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1309\n",
      "- Mean Absolute Error: 0.1013\n",
      "- R2 Score: 0.3125\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1582\n",
      "- Mean Absolute Error: 0.1194\n",
      "- R2 Score: 0.1847\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create list of training algorithms\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Lasso\": Lasso(random_state=12),\n",
    "    \"Ridge\": Ridge(random_state=23),\n",
    "    \"SVR\": SVR(),\n",
    "    \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=34),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(random_state=45),\n",
    "    \"XGBRegressor\": XGBRegressor(random_state=56),\n",
    "    \"AdaBoost Regressor\": AdaBoostRegressor(random_state=67)\n",
    "}\n",
    "model_list = []\n",
    "r2_list =[]\n",
    "\n",
    "# Define the train and test datasets\n",
    "X_train=X_train_ori\n",
    "X_test=X_test_ori\n",
    "\n",
    "# display the model evaluation for each algorithm\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate Train and Test dataset\n",
    "    model_train_mae , model_train_rmse, model_train_r2 = evaluate_model(y_train, y_train_pred)\n",
    "\n",
    "    model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    \n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
    "    r2_list.append(model_test_r2)\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>R2_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>0.326226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.298083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.203450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.191035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoost Regressor</td>\n",
       "      <td>0.184693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Neighbors Regressor</td>\n",
       "      <td>0.027714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>-0.002677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVR</td>\n",
       "      <td>-0.038405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>-0.308159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model Name  R2_Score\n",
       "6  Random Forest Regressor  0.326226\n",
       "7             XGBRegressor  0.298083\n",
       "0        Linear Regression  0.203450\n",
       "2                    Ridge  0.191035\n",
       "8       AdaBoost Regressor  0.184693\n",
       "4    K-Neighbors Regressor  0.027714\n",
       "1                    Lasso -0.002677\n",
       "3                      SVR -0.038405\n",
       "5            Decision Tree -0.308159"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_original_predictors = pd.DataFrame(list(zip(model_list, r2_list)), columns=['Model Name', 'R2_Score']).sort_values(by=[\"R2_Score\"],ascending=False)\n",
    "result_original_predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Scaled Value Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1382\n",
      "- Mean Absolute Error: 0.0972\n",
      "- R2 Score: 0.2346\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1569\n",
      "- Mean Absolute Error: 0.1110\n",
      "- R2 Score: 0.1980\n",
      "===================================\n",
      "\n",
      "\n",
      "Lasso\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1579\n",
      "- Mean Absolute Error: 0.1232\n",
      "- R2 Score: 0.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1755\n",
      "- Mean Absolute Error: 0.1333\n",
      "- R2 Score: -0.0034\n",
      "===================================\n",
      "\n",
      "\n",
      "Ridge\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1381\n",
      "- Mean Absolute Error: 0.0969\n",
      "- R2 Score: 0.2355\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1564\n",
      "- Mean Absolute Error: 0.1104\n",
      "- R2 Score: 0.2031\n",
      "===================================\n",
      "\n",
      "\n",
      "SVR\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1111\n",
      "- Mean Absolute Error: 0.0847\n",
      "- R2 Score: 0.5049\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1606\n",
      "- Mean Absolute Error: 0.1156\n",
      "- R2 Score: 0.1600\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1150\n",
      "- Mean Absolute Error: 0.0792\n",
      "- R2 Score: 0.4695\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1588\n",
      "- Mean Absolute Error: 0.1088\n",
      "- R2 Score: 0.1783\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.2004\n",
      "- Mean Absolute Error: 0.1266\n",
      "- R2 Score: -0.3082\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0493\n",
      "- Mean Absolute Error: 0.0330\n",
      "- R2 Score: 0.9027\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1441\n",
      "- Mean Absolute Error: 0.0980\n",
      "- R2 Score: 0.3232\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBRegressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0127\n",
      "- Mean Absolute Error: 0.0080\n",
      "- R2 Score: 0.9936\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1468\n",
      "- Mean Absolute Error: 0.1008\n",
      "- R2 Score: 0.2981\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1309\n",
      "- Mean Absolute Error: 0.1013\n",
      "- R2 Score: 0.3125\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1583\n",
      "- Mean Absolute Error: 0.1195\n",
      "- R2 Score: 0.1833\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create list of training algorithms\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Lasso\": Lasso(random_state=12),\n",
    "    \"Ridge\": Ridge(random_state=23),\n",
    "    \"SVR\": SVR(),\n",
    "    \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=34),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(random_state=45),\n",
    "    \"XGBRegressor\": XGBRegressor(random_state=56),\n",
    "    \"AdaBoost Regressor\": AdaBoostRegressor(random_state=67)\n",
    "}\n",
    "model_list = []\n",
    "r2_list =[]\n",
    "\n",
    "# Define the train and test datasets\n",
    "X_train=X_train_std_scaled\n",
    "X_test=X_test_std_scaled\n",
    "\n",
    "# display the model evaluation for each algorithm\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate Train and Test dataset\n",
    "    model_train_mae , model_train_rmse, model_train_r2 = evaluate_model(y_train, y_train_pred)\n",
    "\n",
    "    model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    \n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
    "    r2_list.append(model_test_r2)\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>R2_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>0.323161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.298083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.203145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.198043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoost Regressor</td>\n",
       "      <td>0.183275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Neighbors Regressor</td>\n",
       "      <td>0.178348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVR</td>\n",
       "      <td>0.160034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>-0.003373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>-0.308159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model Name  R2_Score\n",
       "6  Random Forest Regressor  0.323161\n",
       "7             XGBRegressor  0.298083\n",
       "2                    Ridge  0.203145\n",
       "0        Linear Regression  0.198043\n",
       "8       AdaBoost Regressor  0.183275\n",
       "4    K-Neighbors Regressor  0.178348\n",
       "3                      SVR  0.160034\n",
       "1                    Lasso -0.003373\n",
       "5            Decision Tree -0.308159"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_std_scaled_predictors = pd.DataFrame(list(zip(model_list, r2_list)), columns=['Model Name', 'R2_Score']).sort_values(by=[\"R2_Score\"],ascending=False)\n",
    "result_std_scaled_predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robust Scaled Value Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1381\n",
      "- Mean Absolute Error: 0.0969\n",
      "- R2 Score: 0.2348\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1612\n",
      "- Mean Absolute Error: 0.1136\n",
      "- R2 Score: 0.1531\n",
      "===================================\n",
      "\n",
      "\n",
      "Lasso\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1579\n",
      "- Mean Absolute Error: 0.1232\n",
      "- R2 Score: 0.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1755\n",
      "- Mean Absolute Error: 0.1333\n",
      "- R2 Score: -0.0034\n",
      "===================================\n",
      "\n",
      "\n",
      "Ridge\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1381\n",
      "- Mean Absolute Error: 0.0969\n",
      "- R2 Score: 0.2355\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1608\n",
      "- Mean Absolute Error: 0.1135\n",
      "- R2 Score: 0.1576\n",
      "===================================\n",
      "\n",
      "\n",
      "SVR\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1121\n",
      "- Mean Absolute Error: 0.0853\n",
      "- R2 Score: 0.4965\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1621\n",
      "- Mean Absolute Error: 0.1178\n",
      "- R2 Score: 0.1440\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1186\n",
      "- Mean Absolute Error: 0.0826\n",
      "- R2 Score: 0.4365\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1645\n",
      "- Mean Absolute Error: 0.1144\n",
      "- R2 Score: 0.1180\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.2107\n",
      "- Mean Absolute Error: 0.1441\n",
      "- R2 Score: -0.4469\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0493\n",
      "- Mean Absolute Error: 0.0331\n",
      "- R2 Score: 0.9025\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1575\n",
      "- Mean Absolute Error: 0.1166\n",
      "- R2 Score: 0.1916\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBRegressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0127\n",
      "- Mean Absolute Error: 0.0080\n",
      "- R2 Score: 0.9936\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1752\n",
      "- Mean Absolute Error: 0.1326\n",
      "- R2 Score: 0.0002\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1309\n",
      "- Mean Absolute Error: 0.1013\n",
      "- R2 Score: 0.3125\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1625\n",
      "- Mean Absolute Error: 0.1224\n",
      "- R2 Score: 0.1399\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create list of training algorithms\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Lasso\": Lasso(random_state=12),\n",
    "    \"Ridge\": Ridge(random_state=23),\n",
    "    \"SVR\": SVR(),\n",
    "    \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=34),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(random_state=45),\n",
    "    \"XGBRegressor\": XGBRegressor(random_state=56),\n",
    "    \"AdaBoost Regressor\": AdaBoostRegressor(random_state=67)\n",
    "}\n",
    "model_list = []\n",
    "r2_list =[]\n",
    "\n",
    "# Define the train and test datasets\n",
    "X_train=X_train_rob_scaled\n",
    "X_test=X_test_rob_scaled\n",
    "\n",
    "# display the model evaluation for each algorithm\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate Train and Test dataset\n",
    "    model_train_mae , model_train_rmse, model_train_r2 = evaluate_model(y_train, y_train_pred)\n",
    "\n",
    "    model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    \n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
    "    r2_list.append(model_test_r2)\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>R2_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>0.191566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.157598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.153120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVR</td>\n",
       "      <td>0.143969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoost Regressor</td>\n",
       "      <td>0.139864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Neighbors Regressor</td>\n",
       "      <td>0.117987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.000211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>-0.003373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>-0.446869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model Name  R2_Score\n",
       "6  Random Forest Regressor  0.191566\n",
       "2                    Ridge  0.157598\n",
       "0        Linear Regression  0.153120\n",
       "3                      SVR  0.143969\n",
       "8       AdaBoost Regressor  0.139864\n",
       "4    K-Neighbors Regressor  0.117987\n",
       "7             XGBRegressor  0.000211\n",
       "1                    Lasso -0.003373\n",
       "5            Decision Tree -0.446869"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_rob_scaled_predictors = pd.DataFrame(list(zip(model_list, r2_list)), columns=['Model Name', 'R2_Score']).sort_values(by=[\"R2_Score\"],ascending=False)\n",
    "result_rob_scaled_predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models performance of the reduced features dataset are worse than before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Retraining with Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try another feature selection method, the Recursive Feature Elimination (RFE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Dataset for Modelling Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "df = pd.read_csv('/home/er_bim/productivity-prediction/notebooks/data/worker_productivity_processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we separate the features in the dataset as predictors and target.\n",
    "\n",
    "The target (y variable) feature is `actual_producticity`, thus the rest of the of the features after the feature `date` is eliminated are the predictors (X variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predictors consist of 11 columns and 1108 rows.\n",
      "\n",
      "The target column is actual_productivity which consist of 1108 rows.\n"
     ]
    }
   ],
   "source": [
    "# set the X variables\n",
    "X = df.drop(columns=['date', 'actual_productivity'],axis=1)\n",
    "\n",
    "# set the y variable\n",
    "y = df['actual_productivity']\n",
    "\n",
    "# recheck the shape of each variable\n",
    "print(f\"The predictors consist of {X.shape[1]} columns and {X.shape[0]} rows.\\n\" )\n",
    "print(f\"The target column is {y.name} which consist of {y.shape[0]} rows.\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data splitting, 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create instance for numerical and categorical features\n",
    "num = X._get_numeric_data().columns\n",
    "cat = X.drop(num, axis = 1).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we do the column transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler = StandardScaler()\n",
    "\n",
    "# create column transformer pipeline for standard scaled numerical features\n",
    "preprocessor = ColumnTransformer([(\"OneHotEncoder\", cat_encoder, cat), \n",
    "                                  (\"StandardScaler\", std_scaler, num)]\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and transform X_train with original value in numerical features\n",
    "X_train_std_scaled = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# transform X_test with original value in numerical features\n",
    "X_test_std_scaled = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training with RFE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimator in RFE feature selection is Random Forest Regressor.\n",
    "\n",
    "We need to specify the number of features to be included in the training with RFE method.\n",
    "\n",
    "To simplify the training process, we use the same algorithm that produce the best performance, include its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 2, R score: 0.1986\n",
      "Number of features: 3, R score: 0.2474\n",
      "Number of features: 4, R score: 0.3050\n",
      "Number of features: 5, R score: 0.3215\n",
      "Number of features: 6, R score: 0.3720\n",
      "Number of features: 7, R score: 0.3748\n",
      "Number of features: 8, R score: 0.3918\n",
      "Number of features: 9, R score: 0.3872\n",
      "Number of features: 10, R score: 0.3899\n",
      "Number of features: 11, R score: 0.4027\n"
     ]
    }
   ],
   "source": [
    "# define the maximum n_features\n",
    "total_cols = len(df.columns) -1\n",
    "\n",
    "# create the blank list for s-squared scores\n",
    "r2_scores = []\n",
    "\n",
    "for n_features in range(2, total_cols):\n",
    "    # initialize the RFE with the specified number of features\n",
    "    rfe = RFE(estimator=RandomForestRegressor(random_state=45), n_features_to_select=n_features)\n",
    "    \n",
    "    # set the training algorithm\n",
    "    model = RandomForestRegressor(n_estimators= 300, \n",
    "                                 min_samples_split= 5, \n",
    "                                 min_samples_leaf= 4, \n",
    "                                 max_depth= 20, \n",
    "                                 criterion= 'squared_error', \n",
    "                                 random_state=45\n",
    "                                 )\n",
    "    \n",
    "    # define the pipeline\n",
    "    rf_pipeline = Pipeline(steps=[('c',rfe),('m',model)])\n",
    "    \n",
    "    # fit the model\n",
    "    rf_pipeline.fit(X_train_std_scaled, y_train)\n",
    "    \n",
    "    # predict on the test set\n",
    "    y_pred = rf_pipeline.predict(X_test_std_scaled)\n",
    "    \n",
    "    # calculate the R score\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # store the result to the blank list\n",
    "    r2_scores.append((n_features, r2))\n",
    "\n",
    "    # print the R score for the current number of features\n",
    "    print(f\"Number of features: {n_features}, R score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model performance is determined by 11 features resulted from the RFE.\n",
    "\n",
    "Now let's we try to do the cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the model training with 11 features in RFE process\n",
    "rfe = RFE(estimator=RandomForestRegressor(random_state=45), n_features_to_select=11)\n",
    "model = RandomForestRegressor(n_estimators= 300, \n",
    "                                 min_samples_split= 5, \n",
    "                                 min_samples_leaf= 4, \n",
    "                                 max_depth= 20, \n",
    "                                 criterion= 'squared_error', \n",
    "                                 random_state=45\n",
    "                                 )\n",
    "    \n",
    "# define the pipeline\n",
    "rf_pipeline = Pipeline(steps=[('c',rfe),('m',model)]).fit(X_train_std_scaled, y_train)\n",
    "\n",
    "# fit the model\n",
    "#rf_pipeline.fit(X_train_std_scaled, y_train)\n",
    "    \n",
    "# predict on the test set\n",
    "y_pred = rf_pipeline.predict(X_test_std_scaled)\n",
    "    \n",
    "# calculate the R score\n",
    "r2 = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the library\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# predicting Cross Validation Score\n",
    "cv_rf_pipeline = cross_val_score(estimator = rf_pipeline, X = X_test_std_scaled, y = y_test, cv = 5, scoring='r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R score: 0.4027\n",
      "Cross-Validated R score:  0.3214\n"
     ]
    }
   ],
   "source": [
    "print('R score:', round( rf_pipeline.score(X_test_std_scaled, y_test),4) )\n",
    "print(\"Cross-Validated R score: \", round(cv_rf_pipeline.mean(),4) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a better R score with the RFE feature selection method.\n",
    "\n",
    "The parameters applied in the RFE are: Random Forest Regressor estimator with 11 features.\n",
    "\n",
    "After the features selected by RFE, then followed by train the model with Random Forest Regressor contains this paramaters: \n",
    "- n_estimators= 300, \n",
    "- min_samples_split= 5\n",
    "- min_samples_leaf= 4\n",
    "- max_depth= 20 \n",
    "- criterion= 'squared_error'\n",
    "- random_state=45\n",
    "\n",
    "Then folowed by cross-validating the model with 5 fold to get the mean R score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Retraining with Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try the Principal Comoonent Analysis (PCA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Dataset for Modelling Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "df = pd.read_csv('/home/er_bim/productivity-prediction/notebooks/data/worker_productivity_processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we separate the features in the dataset as predictors and target.\n",
    "\n",
    "The target (y variable) feature is `actual_producticity`, thus the rest of the of the features after the feature `date` is eliminated are the predictors (X variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predictors consist of 11 columns and 1108 rows.\n",
      "\n",
      "The target column is actual_productivity which consist of 1108 rows.\n"
     ]
    }
   ],
   "source": [
    "# set the X variables\n",
    "X = df.drop(columns=['date', 'actual_productivity'],axis=1)\n",
    "\n",
    "# set the y variable\n",
    "y = df['actual_productivity']\n",
    "\n",
    "# recheck the shape of each variable\n",
    "print(f\"The predictors consist of {X.shape[1]} columns and {X.shape[0]} rows.\\n\" )\n",
    "print(f\"The target column is {y.name} which consist of {y.shape[0]} rows.\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data splitting, 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create instance for numerical and categorical features\n",
    "num = X._get_numeric_data().columns\n",
    "cat = X.drop(num, axis = 1).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we do the column transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column transformer pipeline for standard scaled numerical features\n",
    "preprocessor = ColumnTransformer([(\"OneHotEncoder\", cat_encoder, cat), \n",
    "                                  (\"passthrough\", \"passthrough\", num)]\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and transform X original value in numerical features\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# transform X_test with original value in numerical features\n",
    "X_test_transformed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training with PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to find the n_components with the best result.\n",
    "\n",
    "To simplify the training process, we use the same algorithm that produce the best performance, include its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components: 2, R score: -0.0397\n",
      "Number of components: 3, R score: 0.0708\n",
      "Number of components: 4, R score: 0.1756\n",
      "Number of components: 5, R score: 0.1639\n",
      "Number of components: 6, R score: 0.2245\n",
      "Number of components: 7, R score: 0.2735\n",
      "Number of components: 8, R score: 0.2945\n",
      "Number of components: 9, R score: 0.2775\n",
      "Number of components: 10, R score: 0.2608\n",
      "Number of components: 11, R score: 0.2599\n"
     ]
    }
   ],
   "source": [
    "# define the maximum n_features\n",
    "total_cols = len(df.columns) -1\n",
    "\n",
    "# create the blank list for s-squared scores\n",
    "r2_scores = []\n",
    "\n",
    "for n_components in range(2, total_cols):\n",
    "    # initialize the PCA with the specified number of components\n",
    "    pca = PCA(n_components=n_components, random_state=97)\n",
    "    \n",
    "    # fit and transfor to the predictors\n",
    "    X_train_PCA = pca.fit_transform(X_train_transformed)\n",
    "    X_test_PCA = pca.fit_transform(X_test_transformed)\n",
    "    \n",
    "    # set the training algorithm\n",
    "    model = RandomForestRegressor(n_estimators= 300, \n",
    "                                 min_samples_split= 5, \n",
    "                                 min_samples_leaf= 4, \n",
    "                                 max_depth= 20, \n",
    "                                 criterion= 'squared_error', \n",
    "                                 random_state=45\n",
    "                                 )\n",
    "    \n",
    "    # fit the model\n",
    "    model.fit(X_train_PCA, y_train)\n",
    "    \n",
    "    # predict on the test set\n",
    "    y_pred = model.predict(X_test_PCA)\n",
    "    \n",
    "    # calculate the R score\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # store the result to the blank list\n",
    "    r2_scores.append((n_features, r2))\n",
    "\n",
    "    # print the R score for the current number of features\n",
    "    print(f\"Number of components: {n_components}, R score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model performance is determined by 11 features resulted from the RFE.\n",
    "\n",
    "Now let's we try to do the cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R score with the PCA feature selection method is worse than the one resulted from the RFE method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we decide to take the best model to the production phase, we need to try to tune the parameters one more time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters used by model:\n",
      "\n",
      "{'c': RFE(estimator=RandomForestRegressor(random_state=45), n_features_to_select=11),\n",
      " 'c__estimator': RandomForestRegressor(random_state=45),\n",
      " 'c__estimator__bootstrap': True,\n",
      " 'c__estimator__ccp_alpha': 0.0,\n",
      " 'c__estimator__criterion': 'squared_error',\n",
      " 'c__estimator__max_depth': None,\n",
      " 'c__estimator__max_features': 1.0,\n",
      " 'c__estimator__max_leaf_nodes': None,\n",
      " 'c__estimator__max_samples': None,\n",
      " 'c__estimator__min_impurity_decrease': 0.0,\n",
      " 'c__estimator__min_samples_leaf': 1,\n",
      " 'c__estimator__min_samples_split': 2,\n",
      " 'c__estimator__min_weight_fraction_leaf': 0.0,\n",
      " 'c__estimator__monotonic_cst': None,\n",
      " 'c__estimator__n_estimators': 100,\n",
      " 'c__estimator__n_jobs': None,\n",
      " 'c__estimator__oob_score': False,\n",
      " 'c__estimator__random_state': 45,\n",
      " 'c__estimator__verbose': 0,\n",
      " 'c__estimator__warm_start': False,\n",
      " 'c__importance_getter': 'auto',\n",
      " 'c__n_features_to_select': 11,\n",
      " 'c__step': 1,\n",
      " 'c__verbose': 0,\n",
      " 'm': RandomForestRegressor(max_depth=20, min_samples_leaf=4, min_samples_split=5,\n",
      "                      n_estimators=300, random_state=45),\n",
      " 'm__bootstrap': True,\n",
      " 'm__ccp_alpha': 0.0,\n",
      " 'm__criterion': 'squared_error',\n",
      " 'm__max_depth': 20,\n",
      " 'm__max_features': 1.0,\n",
      " 'm__max_leaf_nodes': None,\n",
      " 'm__max_samples': None,\n",
      " 'm__min_impurity_decrease': 0.0,\n",
      " 'm__min_samples_leaf': 4,\n",
      " 'm__min_samples_split': 5,\n",
      " 'm__min_weight_fraction_leaf': 0.0,\n",
      " 'm__monotonic_cst': None,\n",
      " 'm__n_estimators': 300,\n",
      " 'm__n_jobs': None,\n",
      " 'm__oob_score': False,\n",
      " 'm__random_state': 45,\n",
      " 'm__verbose': 0,\n",
      " 'm__warm_start': False,\n",
      " 'memory': None,\n",
      " 'steps': [('c',\n",
      "            RFE(estimator=RandomForestRegressor(random_state=45), n_features_to_select=11)),\n",
      "           ('m',\n",
      "            RandomForestRegressor(max_depth=20, min_samples_leaf=4, min_samples_split=5,\n",
      "                      n_estimators=300, random_state=45))],\n",
      " 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "# recall the best model with feature selection\n",
    "rfe_result = round(cv_rf_pipeline.mean(), 4)\n",
    "\n",
    "# check the parameters used by the model\n",
    "from pprint import pprint\n",
    "print('Parameters used by model:\\n')\n",
    "pprint(rf_pipeline.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the pipeline\n",
    "rfe = RFE(estimator=RandomForestRegressor(random_state=45), n_features_to_select=11)\n",
    "model = RandomForestRegressor(random_state=45)\n",
    "    \n",
    "# define the pipeline\n",
    "rf_pipeline = Pipeline(steps=[('c',rfe),('m',model)])\n",
    "\n",
    "# define the RFE parameter\n",
    "features = {'c__n_features_to_select': \n",
    "# define the modelling parameters\n",
    "param_grid = {\n",
    "    'm__criterion': [\"squared_error\", \"absolute_error\", \"friedman_mse\", \"poisson\"],\n",
    "    'm__n_estimators': [100, 200, 300],\n",
    "    'm__max_depth': [10, 20, 30, None],\n",
    "    'm__min_samples_split': [2, 5, 10],\n",
    "    'm__min_samples_leaf': [1, 2, 4]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'m__criterion': 'poisson', 'm__max_depth': 20, 'm__min_samples_leaf': 4, 'm__min_samples_split': 2, 'm__n_estimators': 300}\n",
      "Best Model Test Set R2: 0.4003\n"
     ]
    }
   ],
   "source": [
    "# Set up the GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf_pipeline, param_grid=param_grid, cv=5, n_jobs=-1, scoring='r2')\n",
    "\n",
    "# Define the train and test datasets\n",
    "X_train=X_train_std_scaled\n",
    "X_test=X_test_std_scaled\n",
    "\n",
    "# Fit the GridSearchCV to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(f\"Best parameters found: {best_params}\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "r2_value_gridsearch = r2_score(y_test, y_test_pred)\n",
    "print(f\"Best Model Test Set R2: {r2_value_gridsearch:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
