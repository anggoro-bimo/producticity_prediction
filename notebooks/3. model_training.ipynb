{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will try to train the dataset using several different algorithms and compare them to get the best model trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libaries and Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression, Ridge,Lasso\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "df = pd.read_csv('/home/er_bim/productivity-prediction/notebooks/data/worker_productivity_processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Dataset for Modelling Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate the predictors and target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we separate the features in the dataset as predictors and target.\n",
    "\n",
    "The target (y variable) feature is `actual_producticity`, thus the rest of the of the features after the feature `date` is eliminated are the predictors (X variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predictors consist of 11 columns and 1108 rows.\n",
      "\n",
      "The target column is actual_productivity which consist of 1108 rows.\n"
     ]
    }
   ],
   "source": [
    "# set the X variables\n",
    "X = df.drop(columns=['date', 'actual_productivity'],axis=1)\n",
    "\n",
    "# set the y variable\n",
    "y = df['actual_productivity']\n",
    "\n",
    "# recheck the shape of each variable\n",
    "print(f\"The predictors consist of {X.shape[1]} columns and {X.shape[0]} rows.\\n\" )\n",
    "print(f\"The target column is {y.name} which consist of {y.shape[0]} rows.\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>department</th>\n",
       "      <th>day</th>\n",
       "      <th>team</th>\n",
       "      <th>targeted_productivity</th>\n",
       "      <th>smv</th>\n",
       "      <th>wip</th>\n",
       "      <th>over_time</th>\n",
       "      <th>incentive</th>\n",
       "      <th>no_of_style_change</th>\n",
       "      <th>no_of_workers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Week1</td>\n",
       "      <td>sewing</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>26.16</td>\n",
       "      <td>1108</td>\n",
       "      <td>7080</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Week1</td>\n",
       "      <td>finishing</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.94</td>\n",
       "      <td>802</td>\n",
       "      <td>960</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Week1</td>\n",
       "      <td>sewing</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>11</td>\n",
       "      <td>0.80</td>\n",
       "      <td>11.41</td>\n",
       "      <td>968</td>\n",
       "      <td>3660</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    week department       day  team  targeted_productivity    smv   wip  \\\n",
       "0  Week1     sewing  Thursday     8                   0.80  26.16  1108   \n",
       "1  Week1  finishing  Thursday     1                   0.75   3.94   802   \n",
       "2  Week1     sewing  Thursday    11                   0.80  11.41   968   \n",
       "\n",
       "   over_time  incentive  no_of_style_change  no_of_workers  \n",
       "0       7080         98                   0             59  \n",
       "1        960          0                   0              8  \n",
       "2       3660         50                   0             31  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recheck the predictors\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.940725\n",
       "1    0.886500\n",
       "2    0.800570\n",
       "Name: actual_productivity, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recheck the target column\n",
    "y.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Dataset into Train and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will split the dataset into 70% train and 30% test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the predictors value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categorical features need to be encoded to fit the model training; I chose the one-hot encoding method for this dataset.\n",
    "\n",
    "For the numerical features, I want to do the experiment that both will be trained; the first one will be trained as the original value, and the second will be transformed first to make the value compacted. I choose the robust scaler transformation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create instance for numerical and categorical features\n",
    "num = X._get_numeric_data().columns\n",
    "cat = X.drop(num, axis = 1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libaries for column transformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "rob_scaler = RobustScaler()\n",
    "cat_encoder = OneHotEncoder()\n",
    "\n",
    "# create column transformer pipeline for original value numerical features\n",
    "preprocessor1 = ColumnTransformer([(\"OneHotEncoder\", cat_encoder, cat), \n",
    "                                  (\"passthrough\", \"passthrough\", num)]\n",
    "                                )\n",
    "\n",
    "# create column transformer pipeline for standard scaled numerical features\n",
    "preprocessor2 = ColumnTransformer([(\"OneHotEncoder\", cat_encoder, cat), \n",
    "                                  (\"StandardScaler\", std_scaler, num)]\n",
    "                                )\n",
    "\n",
    "# create column transformer pipeline for robust scaled numerical features\n",
    "preprocessor3 = ColumnTransformer([(\"OneHotEncoder\", cat_encoder, cat), \n",
    "                                  (\"RobustScaler\", rob_scaler, num)]\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic statistical summary of predictors with original value: \n",
      "\n",
      "               13          14          15           16            17  \\\n",
      "count  775.000000  775.000000  775.000000   775.000000    775.000000   \n",
      "mean     6.597419    0.739097   14.724477   928.640000   4464.277419   \n",
      "std      3.461564    0.076885   10.894635   270.193726   3228.813681   \n",
      "min      1.000000    0.500000    2.900000     7.000000      0.000000   \n",
      "25%      4.000000    0.700000    3.940000   814.000000   1440.000000   \n",
      "50%      7.000000    0.750000   14.890000   841.000000   3960.000000   \n",
      "75%     10.000000    0.800000   23.475000  1069.000000   6900.000000   \n",
      "max     12.000000    0.800000   54.560000  1871.000000  15000.000000   \n",
      "\n",
      "               18          19          20  \n",
      "count  775.000000  775.000000  775.000000  \n",
      "mean    23.873548    0.150968   33.388387  \n",
      "std     27.862703    0.427324   22.065152  \n",
      "min      0.000000    0.000000    2.000000  \n",
      "25%      0.000000    0.000000    9.000000  \n",
      "50%      0.000000    0.000000   34.000000  \n",
      "75%     50.000000    0.000000   57.000000  \n",
      "max    113.000000    2.000000   60.000000  \n"
     ]
    }
   ],
   "source": [
    "# fit and transform X_train with original value in numerical features\n",
    "X_train_ori = preprocessor1.fit_transform(X_train)\n",
    "\n",
    "# transform X_test with original value in numerical features\n",
    "X_test_ori = preprocessor1.transform(X_test)\n",
    "\n",
    "# show the statistical summary\n",
    "print(f\"Basic statistical summary of predictors with original value: \\n\\n{pd.DataFrame(X_train_ori).loc[:, 13:20].describe()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic statistical summary of predictors with standard scaled value: \n",
      "\n",
      "                 13            14            15            16            17  \\\n",
      "count  7.750000e+02  7.750000e+02  7.750000e+02  7.750000e+02  7.750000e+02   \n",
      "mean  -5.042561e-17  5.500976e-16 -2.131628e-16  6.417805e-17  8.136860e-17   \n",
      "std    1.000646e+00  1.000646e+00  1.000646e+00  1.000646e+00  1.000646e+00   \n",
      "min   -1.618065e+00 -3.111799e+00 -1.086050e+00 -3.413237e+00 -1.383530e+00   \n",
      "25%   -7.508447e-01 -5.088371e-01 -9.905281e-01 -4.245622e-01 -9.372577e-01   \n",
      "50%    1.163753e-01  1.419034e-01  1.520285e-02 -3.245693e-01 -1.562813e-01   \n",
      "75%    9.835954e-01  7.926439e-01  8.037143e-01  5.198146e-01  7.548579e-01   \n",
      "max    1.561742e+00  7.926439e-01  3.658796e+00  3.489972e+00  3.265139e+00   \n",
      "\n",
      "                 18            19            20  \n",
      "count  7.750000e+02  7.750000e+02  7.750000e+02  \n",
      "mean  -1.948262e-17 -4.125732e-17 -1.100195e-16  \n",
      "std    1.000646e+00  1.000646e+00  1.000646e+00  \n",
      "min   -8.573815e-01 -3.535147e-01 -1.423451e+00  \n",
      "25%   -8.573815e-01 -3.535147e-01 -1.106004e+00  \n",
      "50%   -8.573815e-01 -3.535147e-01  2.773640e-02  \n",
      "75%    9.382910e-01 -3.535147e-01  1.070777e+00  \n",
      "max    3.200838e+00  4.329799e+00  1.206826e+00  \n"
     ]
    }
   ],
   "source": [
    "# fit and transform X_train with original value in numerical features\n",
    "X_train_std_scaled = preprocessor2.fit_transform(X_train)\n",
    "\n",
    "# transform X_test with original value in numerical features\n",
    "X_test_std_scaled = preprocessor2.transform(X_test)\n",
    "\n",
    "# show the statistical summary\n",
    "print(f\"Basic statistical summary of predictors with standard scaled value: \\n\\n{pd.DataFrame(X_train_std_scaled).loc[:, 13:20].describe()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic statistical summary of predictors with robust scaled value: \n",
      "\n",
      "               13          14          15          16          17          18  \\\n",
      "count  775.000000  775.000000  775.000000  775.000000  775.000000  775.000000   \n",
      "mean    -0.067097   -0.109032   -0.008473    0.343686    0.092359    0.477471   \n",
      "std      0.576927    0.768852    0.557698    1.059583    0.591358    0.557254   \n",
      "min     -1.000000   -2.500000   -0.613770   -3.270588   -0.725275    0.000000   \n",
      "25%     -0.500000   -0.500000   -0.560532   -0.105882   -0.461538    0.000000   \n",
      "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "75%      0.500000    0.500000    0.439468    0.894118    0.538462    1.000000   \n",
      "max      0.833333    0.500000    2.030714    4.039216    2.021978    2.260000   \n",
      "\n",
      "               19          20  \n",
      "count  775.000000  775.000000  \n",
      "mean     0.150968   -0.012742  \n",
      "std      0.427324    0.459691  \n",
      "min      0.000000   -0.666667  \n",
      "25%      0.000000   -0.520833  \n",
      "50%      0.000000    0.000000  \n",
      "75%      0.000000    0.479167  \n",
      "max      2.000000    0.541667  \n"
     ]
    }
   ],
   "source": [
    "# fit and transform X_train with original value in numerical features\n",
    "X_train_rob_scaled = preprocessor3.fit_transform(X_train)\n",
    "\n",
    "# transform X_test with original value in numerical features\n",
    "X_test_rob_scaled = preprocessor2.transform(X_test)\n",
    "\n",
    "# show the statistical summary\n",
    "print(f\"Basic statistical summary of predictors with robust scaled value: \\n\\n{pd.DataFrame(X_train_rob_scaled).loc[:, 13:20].describe()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try to do the modelling process of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the function for model evaluation \n",
    "def evaluate_model(true, predicted):\n",
    "    mae = mean_absolute_error(true, predicted)\n",
    "    mse = mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(true, predicted))\n",
    "    r2_square = r2_score(true, predicted)\n",
    "    return mae, rmse, r2_square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Value Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1262\n",
      "- Mean Absolute Error: 0.0902\n",
      "- R2 Score: 0.3619\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1457\n",
      "- Mean Absolute Error: 0.0998\n",
      "- R2 Score: 0.3081\n",
      "===================================\n",
      "\n",
      "\n",
      "Lasso\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1541\n",
      "- Mean Absolute Error: 0.1190\n",
      "- R2 Score: 0.0475\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1727\n",
      "- Mean Absolute Error: 0.1296\n",
      "- R2 Score: 0.0284\n",
      "===================================\n",
      "\n",
      "\n",
      "Ridge\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1265\n",
      "- Mean Absolute Error: 0.0912\n",
      "- R2 Score: 0.3586\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1462\n",
      "- Mean Absolute Error: 0.1005\n",
      "- R2 Score: 0.3030\n",
      "===================================\n",
      "\n",
      "\n",
      "SVR\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1542\n",
      "- Mean Absolute Error: 0.1196\n",
      "- R2 Score: 0.0462\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1776\n",
      "- Mean Absolute Error: 0.1326\n",
      "- R2 Score: -0.0273\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1204\n",
      "- Mean Absolute Error: 0.0867\n",
      "- R2 Score: 0.4186\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1735\n",
      "- Mean Absolute Error: 0.1231\n",
      "- R2 Score: 0.0187\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1587\n",
      "- Mean Absolute Error: 0.0900\n",
      "- R2 Score: 0.1796\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0451\n",
      "- Mean Absolute Error: 0.0277\n",
      "- R2 Score: 0.9184\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1338\n",
      "- Mean Absolute Error: 0.0813\n",
      "- R2 Score: 0.4170\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBRegressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0087\n",
      "- Mean Absolute Error: 0.0056\n",
      "- R2 Score: 0.9969\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1382\n",
      "- Mean Absolute Error: 0.0845\n",
      "- R2 Score: 0.3780\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1179\n",
      "- Mean Absolute Error: 0.0879\n",
      "- R2 Score: 0.4423\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1399\n",
      "- Mean Absolute Error: 0.0993\n",
      "- R2 Score: 0.3624\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create list of training algorithms\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Lasso\": Lasso(random_state=12),\n",
    "    \"Ridge\": Ridge(random_state=23),\n",
    "    \"SVR\": SVR(),\n",
    "    \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=34),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(random_state=45),\n",
    "    \"XGBRegressor\": XGBRegressor(random_state=56),\n",
    "    \"AdaBoost Regressor\": AdaBoostRegressor(random_state=67)\n",
    "}\n",
    "model_list = []\n",
    "r2_list =[]\n",
    "\n",
    "# Define the train and test datasets\n",
    "X_train=X_train_ori\n",
    "X_test=X_test_ori\n",
    "\n",
    "# display the model evaluation for each algorithm\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate Train and Test dataset\n",
    "    model_train_mae , model_train_rmse, model_train_r2 = evaluate_model(y_train, y_train_pred)\n",
    "\n",
    "    model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    \n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
    "    r2_list.append(model_test_r2)\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>R2_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>0.416958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.378032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoost Regressor</td>\n",
       "      <td>0.362372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.308071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.303029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.179559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.028436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Neighbors Regressor</td>\n",
       "      <td>0.018704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVR</td>\n",
       "      <td>-0.027336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model Name  R2_Score\n",
       "6  Random Forest Regressor  0.416958\n",
       "7             XGBRegressor  0.378032\n",
       "8       AdaBoost Regressor  0.362372\n",
       "0        Linear Regression  0.308071\n",
       "2                    Ridge  0.303029\n",
       "5            Decision Tree  0.179559\n",
       "1                    Lasso  0.028436\n",
       "4    K-Neighbors Regressor  0.018704\n",
       "3                      SVR -0.027336"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_original_predictors = pd.DataFrame(list(zip(model_list, r2_list)), columns=['Model Name', 'R2_Score']).sort_values(by=[\"R2_Score\"],ascending=False)\n",
    "result_original_predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Scaled Value Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1262\n",
      "- Mean Absolute Error: 0.0902\n",
      "- R2 Score: 0.3614\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1458\n",
      "- Mean Absolute Error: 0.1001\n",
      "- R2 Score: 0.3075\n",
      "===================================\n",
      "\n",
      "\n",
      "Lasso\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1579\n",
      "- Mean Absolute Error: 0.1232\n",
      "- R2 Score: 0.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1755\n",
      "- Mean Absolute Error: 0.1333\n",
      "- R2 Score: -0.0034\n",
      "===================================\n",
      "\n",
      "\n",
      "Ridge\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1262\n",
      "- Mean Absolute Error: 0.0901\n",
      "- R2 Score: 0.3619\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1456\n",
      "- Mean Absolute Error: 0.0997\n",
      "- R2 Score: 0.3088\n",
      "===================================\n",
      "\n",
      "\n",
      "SVR\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1072\n",
      "- Mean Absolute Error: 0.0802\n",
      "- R2 Score: 0.5389\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1497\n",
      "- Mean Absolute Error: 0.1053\n",
      "- R2 Score: 0.2699\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1080\n",
      "- Mean Absolute Error: 0.0712\n",
      "- R2 Score: 0.5319\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1476\n",
      "- Mean Absolute Error: 0.0960\n",
      "- R2 Score: 0.2897\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1587\n",
      "- Mean Absolute Error: 0.0899\n",
      "- R2 Score: 0.1796\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0452\n",
      "- Mean Absolute Error: 0.0278\n",
      "- R2 Score: 0.9182\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1337\n",
      "- Mean Absolute Error: 0.0812\n",
      "- R2 Score: 0.4171\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBRegressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0087\n",
      "- Mean Absolute Error: 0.0056\n",
      "- R2 Score: 0.9969\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1382\n",
      "- Mean Absolute Error: 0.0845\n",
      "- R2 Score: 0.3780\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1209\n",
      "- Mean Absolute Error: 0.0898\n",
      "- R2 Score: 0.4143\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1389\n",
      "- Mean Absolute Error: 0.0988\n",
      "- R2 Score: 0.3711\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create list of training algorithms\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Lasso\": Lasso(random_state=12),\n",
    "    \"Ridge\": Ridge(random_state=23),\n",
    "    \"SVR\": SVR(),\n",
    "    \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=34),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(random_state=45),\n",
    "    \"XGBRegressor\": XGBRegressor(random_state=56),\n",
    "    \"AdaBoost Regressor\": AdaBoostRegressor(random_state=67)\n",
    "}\n",
    "model_list = []\n",
    "r2_list =[]\n",
    "\n",
    "# Define the train and test datasets\n",
    "X_train=X_train_std_scaled\n",
    "X_test=X_test_std_scaled\n",
    "\n",
    "# display the model evaluation for each algorithm\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate Train and Test dataset\n",
    "    model_train_mae , model_train_rmse, model_train_r2 = evaluate_model(y_train, y_train_pred)\n",
    "\n",
    "    model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    \n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
    "    r2_list.append(model_test_r2)\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>R2_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>0.417082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.378032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoost Regressor</td>\n",
       "      <td>0.371123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.308753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.307485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Neighbors Regressor</td>\n",
       "      <td>0.289706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVR</td>\n",
       "      <td>0.269873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.179642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>-0.003373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model Name  R2_Score\n",
       "6  Random Forest Regressor  0.417082\n",
       "7             XGBRegressor  0.378032\n",
       "8       AdaBoost Regressor  0.371123\n",
       "2                    Ridge  0.308753\n",
       "0        Linear Regression  0.307485\n",
       "4    K-Neighbors Regressor  0.289706\n",
       "3                      SVR  0.269873\n",
       "5            Decision Tree  0.179642\n",
       "1                    Lasso -0.003373"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_std_scaled_predictors = pd.DataFrame(list(zip(model_list, r2_list)), columns=['Model Name', 'R2_Score']).sort_values(by=[\"R2_Score\"],ascending=False)\n",
    "result_std_scaled_predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robust Scaled Value Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1262\n",
      "- Mean Absolute Error: 0.0903\n",
      "- R2 Score: 0.3616\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1846\n",
      "- Mean Absolute Error: 0.1438\n",
      "- R2 Score: -0.1108\n",
      "===================================\n",
      "\n",
      "\n",
      "Lasso\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1579\n",
      "- Mean Absolute Error: 0.1232\n",
      "- R2 Score: 0.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1755\n",
      "- Mean Absolute Error: 0.1333\n",
      "- R2 Score: -0.0034\n",
      "===================================\n",
      "\n",
      "\n",
      "Ridge\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1262\n",
      "- Mean Absolute Error: 0.0899\n",
      "- R2 Score: 0.3617\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1801\n",
      "- Mean Absolute Error: 0.1398\n",
      "- R2 Score: -0.0569\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1078\n",
      "- Mean Absolute Error: 0.0812\n",
      "- R2 Score: 0.5340\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1637\n",
      "- Mean Absolute Error: 0.1297\n",
      "- R2 Score: 0.1268\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1124\n",
      "- Mean Absolute Error: 0.0749\n",
      "- R2 Score: 0.4931\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1534\n",
      "- Mean Absolute Error: 0.1017\n",
      "- R2 Score: 0.2327\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.2415\n",
      "- Mean Absolute Error: 0.1631\n",
      "- R2 Score: -0.8998\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0451\n",
      "- Mean Absolute Error: 0.0277\n",
      "- R2 Score: 0.9186\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1636\n",
      "- Mean Absolute Error: 0.1173\n",
      "- R2 Score: 0.1284\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBRegressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0087\n",
      "- Mean Absolute Error: 0.0056\n",
      "- R2 Score: 0.9969\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1828\n",
      "- Mean Absolute Error: 0.1349\n",
      "- R2 Score: -0.0888\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1179\n",
      "- Mean Absolute Error: 0.0879\n",
      "- R2 Score: 0.4423\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1591\n",
      "- Mean Absolute Error: 0.1210\n",
      "- R2 Score: 0.1754\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create list of training algorithms\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Lasso\": Lasso(random_state=12),\n",
    "    \"Ridge\": Ridge(random_state=23),\n",
    "    \"SVR\": SVR(),\n",
    "    \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=34),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(random_state=45),\n",
    "    \"XGBRegressor\": XGBRegressor(random_state=56),\n",
    "    \"AdaBoost Regressor\": AdaBoostRegressor(random_state=67)\n",
    "}\n",
    "model_list = []\n",
    "r2_list =[]\n",
    "\n",
    "# Define the train and test datasets\n",
    "X_train=X_train_rob_scaled\n",
    "X_test=X_test_rob_scaled\n",
    "\n",
    "# display the model evaluation for each algorithm\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate Train and Test dataset\n",
    "    model_train_mae , model_train_rmse, model_train_r2 = evaluate_model(y_train, y_train_pred)\n",
    "\n",
    "    model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    \n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
    "    r2_list.append(model_test_r2)\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>R2_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Neighbors Regressor</td>\n",
       "      <td>0.232735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoost Regressor</td>\n",
       "      <td>0.175414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>0.128368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVR</td>\n",
       "      <td>0.126816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>-0.003373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>-0.056904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>-0.088835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>-0.110838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>-0.899764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model Name  R2_Score\n",
       "4    K-Neighbors Regressor  0.232735\n",
       "8       AdaBoost Regressor  0.175414\n",
       "6  Random Forest Regressor  0.128368\n",
       "3                      SVR  0.126816\n",
       "1                    Lasso -0.003373\n",
       "2                    Ridge -0.056904\n",
       "7             XGBRegressor -0.088835\n",
       "0        Linear Regression -0.110838\n",
       "5            Decision Tree -0.899764"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_rob_scaled_predictors = pd.DataFrame(list(zip(model_list, r2_list)), columns=['Model Name', 'R2_Score']).sort_values(by=[\"R2_Score\"],ascending=False)\n",
    "result_rob_scaled_predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best r-squared value is resulted from the predictors that transformed using standard scaled method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model is: \n",
      "\n",
      "                Model Name  R2_Score\n",
      "6  Random Forest Regressor  0.417082\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best model is: \\n\\n{result_std_scaled_predictors.head(1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 41.71\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestRegressor(random_state=45)\n",
    "rf_model = rf_model.fit(X_train_std_scaled, y_train)\n",
    "y_pred = rf_model.predict(X_test_std_scaled)\n",
    "score = r2_score(y_test, y_pred)*100\n",
    "print(\"Accuracy of the model is %.2f\" %score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning on Random Forest Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to improve the model accuracy value.\n",
    "\n",
    "With the grid search and randomized search cross-validation methods on the Random Forest Regressor defined parameters grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# Define the parameter grid for RandomForestRegressor\n",
    "param_grid = {\n",
    "    'criterion': [\"squared_error\", \"absolute_error\", \"friedman_mse\", \"poisson\"],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "model = RandomForestRegressor(random_state=45)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'criterion': 'poisson', 'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "Best Model Test Set R2: 0.4151\n"
     ]
    }
   ],
   "source": [
    "# Set up the GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, n_jobs=-1, scoring='r2')\n",
    "\n",
    "# Define the train and test datasets\n",
    "X_train=X_train_std_scaled\n",
    "X_test=X_test_std_scaled\n",
    "\n",
    "# Fit the GridSearchCV to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(f\"Best parameters found: {best_params}\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "r2_value_gridsearch = r2_score(y_test, y_test_pred)\n",
    "print(f\"Best Model Test Set R2: {r2_value_gridsearch:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomized Search Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'n_estimators': 300, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_depth': 20, 'criterion': 'squared_error'}\n",
      "Best Model Test Set R2: 0.4210\n"
     ]
    }
   ],
   "source": [
    "# Set up the RandomizedSearchCV\n",
    "rand_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter = 50, cv = 5, n_jobs = -1, scoring='r2', random_state=99)\n",
    "\n",
    "# Define the train and test datasets\n",
    "X_train=X_train_std_scaled\n",
    "X_test=X_test_std_scaled\n",
    "\n",
    "# Fit the GridSearchCV to the data\n",
    "rand_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best model\n",
    "best_params = rand_search.best_params_\n",
    "best_model = rand_search.best_estimator_\n",
    "\n",
    "print(f\"Best parameters found: {best_params}\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "best_r2_randomizedsearch = r2_score(y_test, y_test_pred)\n",
    "print(f\"Best Model Test Set R2: {best_r2_randomizedsearch:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameter tuning experiments with randomized search cross-validation slightly improve the model performance, so we will apply its parameters to the model with the predictors transformed by standard scale method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The acccuracy of the model is 42.099%\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestRegressor(n_estimators= 300, \n",
    "                                 min_samples_split= 5, \n",
    "                                 min_samples_leaf= 4, \n",
    "                                 max_depth= 20, \n",
    "                                 criterion= 'squared_error', \n",
    "                                 random_state=45\n",
    "                                 )\n",
    "rf_model = rf_model.fit(X_train_std_scaled, y_train)\n",
    "y_pred = rf_model.predict(X_test_std_scaled)\n",
    "score = r2_score(y_test, y_pred)*100\n",
    "print(f\"The acccuracy of the model is {score:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters used by model:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'criterion': 'squared_error',\n",
      " 'max_depth': 20,\n",
      " 'max_features': 1.0,\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_samples_leaf': 4,\n",
      " 'min_samples_split': 5,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'monotonic_cst': None,\n",
      " 'n_estimators': 300,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 45,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# check the parameters used by the model\n",
    "from pprint import pprint\n",
    "print('Parameters used by model:\\n')\n",
    "pprint(rf_model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Value</th>\n",
       "      <th>Predicted Value</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>0.850411</td>\n",
       "      <td>0.855127</td>\n",
       "      <td>-0.004717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>0.840889</td>\n",
       "      <td>0.778856</td>\n",
       "      <td>0.062033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>0.545658</td>\n",
       "      <td>0.613793</td>\n",
       "      <td>-0.068135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>0.800437</td>\n",
       "      <td>0.784704</td>\n",
       "      <td>0.015733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>0.259375</td>\n",
       "      <td>0.597991</td>\n",
       "      <td>-0.338616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>0.891556</td>\n",
       "      <td>0.830172</td>\n",
       "      <td>0.061384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>0.802243</td>\n",
       "      <td>0.713657</td>\n",
       "      <td>0.088587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>0.600063</td>\n",
       "      <td>0.602476</td>\n",
       "      <td>-0.002414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>0.272000</td>\n",
       "      <td>0.830835</td>\n",
       "      <td>-0.558835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>0.850362</td>\n",
       "      <td>0.850781</td>\n",
       "      <td>-0.000419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual Value  Predicted Value  Difference\n",
       "343      0.850411         0.855127   -0.004717\n",
       "615      0.840889         0.778856    0.062033\n",
       "605      0.545658         0.613793   -0.068135\n",
       "345      0.800437         0.784704    0.015733\n",
       "476      0.259375         0.597991   -0.338616\n",
       "..            ...              ...         ...\n",
       "717      0.891556         0.830172    0.061384\n",
       "719      0.802243         0.713657    0.088587\n",
       "305      0.600063         0.602476   -0.002414\n",
       "639      0.272000         0.830835   -0.558835\n",
       "486      0.850362         0.850781   -0.000419\n",
       "\n",
       "[333 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df=pd.DataFrame({'Actual Value':y_test,'Predicted Value':y_pred,'Difference':y_test-y_pred})\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.regplot(x=y_test,y=y_pred,ci=None,color ='red');\n",
    "plt.xlabel('Actual');\n",
    "plt.ylabel('Predicted');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
