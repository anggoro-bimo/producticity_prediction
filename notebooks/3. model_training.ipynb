{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will try to train the dataset using several different algorithms and compare them to get the best model trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libaries and Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/er_bim/productivity-prediction/venv/lib/python3.10/site-packages/numpy/_core/getlimits.py:545: UserWarning: Signature b'\\x00\\xd0\\xcc\\xcc\\xcc\\xcc\\xcc\\xcc\\xfb\\xbf\\x00\\x00\\x00\\x00\\x00\\x00' for <class 'numpy.longdouble'> does not match any known type: falling back to type probe function.\n",
      "This warnings indicates broken support for the dtype!\n",
      "  machar = _get_machar(dtype)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression, Ridge,Lasso\n",
    "from xgboost import XGBRegressor\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "df = pd.read_csv('/home/er_bim/productivity-prediction/notebooks/data/worker_productivity_processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Dataset for Modelling Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate the predictors and target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we separate the features in the dataset as predictors and target.\n",
    "\n",
    "The target (y variable) feature is `actual_producticity`, thus the rest of the of the features after the feature `date` is eliminated are the predictors (X variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predictors consist of 11 columns and 1108 rows.\n",
      "\n",
      "The target column is actual_productivity which consist of 1108 rows.\n"
     ]
    }
   ],
   "source": [
    "# set the X variables\n",
    "X = df.drop(columns=['date', 'actual_productivity'],axis=1)\n",
    "\n",
    "# set the y variable\n",
    "y = df['actual_productivity']\n",
    "\n",
    "# recheck the shape of each variable\n",
    "print(f\"The predictors consist of {X.shape[1]} columns and {X.shape[0]} rows.\\n\" )\n",
    "print(f\"The target column is {y.name} which consist of {y.shape[0]} rows.\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>department</th>\n",
       "      <th>day</th>\n",
       "      <th>team</th>\n",
       "      <th>targeted_productivity</th>\n",
       "      <th>smv</th>\n",
       "      <th>wip</th>\n",
       "      <th>over_time</th>\n",
       "      <th>incentive</th>\n",
       "      <th>no_of_style_change</th>\n",
       "      <th>no_of_workers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Week1</td>\n",
       "      <td>sewing</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>26.16</td>\n",
       "      <td>1108</td>\n",
       "      <td>7080</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Week1</td>\n",
       "      <td>finishing</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.94</td>\n",
       "      <td>802</td>\n",
       "      <td>960</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Week1</td>\n",
       "      <td>sewing</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>11</td>\n",
       "      <td>0.80</td>\n",
       "      <td>11.41</td>\n",
       "      <td>968</td>\n",
       "      <td>3660</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    week department       day  team  targeted_productivity    smv   wip  \\\n",
       "0  Week1     sewing  Thursday     8                   0.80  26.16  1108   \n",
       "1  Week1  finishing  Thursday     1                   0.75   3.94   802   \n",
       "2  Week1     sewing  Thursday    11                   0.80  11.41   968   \n",
       "\n",
       "   over_time  incentive  no_of_style_change  no_of_workers  \n",
       "0       7080         98                   0             59  \n",
       "1        960          0                   0              8  \n",
       "2       3660         50                   0             31  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recheck the predictors\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.940725\n",
       "1    0.886500\n",
       "2    0.800570\n",
       "Name: actual_productivity, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recheck the target column\n",
    "y.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Dataset into Train and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will split the dataset into 70% train and 30% test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the predictors value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categorical features need to be encoded to fit the model training; I chose the one-hot encoding method for this dataset.\n",
    "\n",
    "For the numerical features, I want to do the experiment that both will be trained; the first one will be trained as the original value, and the second will be transformed first to make the value compacted. I choose the robust scaler transformation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create instance for numerical and categorical features\n",
    "num = X._get_numeric_data().columns\n",
    "cat = X.drop(num, axis = 1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libaries for column transformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "rob_scaler = RobustScaler()\n",
    "cat_encoder = OneHotEncoder()\n",
    "\n",
    "# create column transformer pipeline for original value numerical features\n",
    "preprocessor1 = ColumnTransformer([(\"OneHotEncoder\", cat_encoder, cat), \n",
    "                                  (\"passthrough\", \"passthrough\", num)]\n",
    "                                )\n",
    "\n",
    "# create column transformer pipeline for standard scaled numerical features\n",
    "preprocessor2 = ColumnTransformer([(\"OneHotEncoder\", cat_encoder, cat), \n",
    "                                  (\"StandardScaler\", std_scaler, num)]\n",
    "                                )\n",
    "\n",
    "# create column transformer pipeline for robust scaled numerical features\n",
    "preprocessor3 = ColumnTransformer([(\"OneHotEncoder\", cat_encoder, cat), \n",
    "                                  (\"RobustScaler\", rob_scaler, num)]\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic statistical summary of predictors with original value: \n",
      "\n",
      "               13          14          15           16            17  \\\n",
      "count  775.000000  775.000000  775.000000   775.000000    775.000000   \n",
      "mean     6.500645    0.736258   15.207742   937.432258   4580.290323   \n",
      "std      3.454344    0.078882   10.949873   282.068981   3275.150126   \n",
      "min      1.000000    0.500000    2.900000     7.000000      0.000000   \n",
      "25%      3.000000    0.700000    3.940000   814.000000   1440.000000   \n",
      "50%      7.000000    0.750000   15.260000   847.000000   4080.000000   \n",
      "75%      9.500000    0.800000   25.605000  1086.000000   6915.000000   \n",
      "max     12.000000    0.800000   51.020000  1871.000000  15000.000000   \n",
      "\n",
      "               18         19          20  \n",
      "count  775.000000  775.00000  775.000000  \n",
      "mean    24.938065    0.16129   34.327742  \n",
      "std     28.094824    0.44727   22.171424  \n",
      "min      0.000000    0.00000    2.000000  \n",
      "25%      0.000000    0.00000    9.000000  \n",
      "50%      0.000000    0.00000   34.000000  \n",
      "75%     50.000000    0.00000   57.000000  \n",
      "max    113.000000    2.00000   89.000000  \n"
     ]
    }
   ],
   "source": [
    "# fit and transform X_train with original value in numerical features\n",
    "X_train_ori = preprocessor1.fit_transform(X_train)\n",
    "\n",
    "# transform X_test with original value in numerical features\n",
    "X_test_ori = preprocessor1.transform(X_test)\n",
    "\n",
    "# show the statistical summary\n",
    "print(f\"Basic statistical summary of predictors with original value: \\n\\n{pd.DataFrame(X_train_ori).loc[:, 13:20].describe()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic statistical summary of predictors with standard scaled value: \n",
      "\n",
      "                 13            14            15            16            17  \\\n",
      "count  7.750000e+02  7.750000e+02  7.750000e+02  7.750000e+02  7.750000e+02   \n",
      "mean  -9.168293e-17  1.001636e-15  3.438110e-17  1.833659e-16  7.793049e-17   \n",
      "std    1.000646e+00  1.000646e+00  1.000646e+00  1.000646e+00  1.000646e+00   \n",
      "min   -1.593413e+00 -2.997006e+00 -1.124734e+00 -3.300728e+00 -1.399401e+00   \n",
      "25%   -1.014058e+00 -4.599446e-01 -1.029694e+00 -4.378786e-01 -9.594425e-01   \n",
      "50%    1.446519e-01  1.743206e-01  4.775563e-03 -3.208104e-01 -1.528520e-01   \n",
      "75%    8.688456e-01  8.085859e-01  9.501455e-01  5.270473e-01  7.133161e-01   \n",
      "max    1.593039e+00  8.085859e-01  3.272676e+00  3.311852e+00  3.183499e+00   \n",
      "\n",
      "                 18            19            20  \n",
      "count  7.750000e+02  7.750000e+02  7.750000e+02  \n",
      "mean   4.125732e-17  2.406677e-17 -2.177470e-17  \n",
      "std    1.000646e+00  1.000646e+00  1.000646e+00  \n",
      "min   -8.882123e-01 -3.608439e-01 -1.459023e+00  \n",
      "25%   -8.882123e-01 -3.608439e-01 -1.143097e+00  \n",
      "50%   -8.882123e-01 -3.608439e-01 -1.479172e-02  \n",
      "75%    8.926242e-01 -3.608439e-01  1.023250e+00  \n",
      "max    3.136478e+00  4.113621e+00  2.467481e+00  \n"
     ]
    }
   ],
   "source": [
    "# fit and transform X_train with original value in numerical features\n",
    "X_train_std_scaled = preprocessor2.fit_transform(X_train)\n",
    "\n",
    "# transform X_test with original value in numerical features\n",
    "X_test_std_scaled = preprocessor2.transform(X_test)\n",
    "\n",
    "# show the statistical summary\n",
    "print(f\"Basic statistical summary of predictors with standard scaled value: \\n\\n{pd.DataFrame(X_train_std_scaled).loc[:, 13:20].describe()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic statistical summary of predictors with robust scaled value: \n",
      "\n",
      "               13          14          15          16          17          18  \\\n",
      "count  775.000000  775.000000  775.000000  775.000000  775.000000  775.000000   \n",
      "mean    -0.076824   -0.137419   -0.002412    0.332472    0.091377    0.498761   \n",
      "std      0.531438    0.788823    0.505418    1.037018    0.598201    0.561896   \n",
      "min     -0.923077   -2.500000   -0.570505   -3.088235   -0.745205    0.000000   \n",
      "25%     -0.615385   -0.500000   -0.522502   -0.121324   -0.482192    0.000000   \n",
      "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "75%      0.384615    0.500000    0.477498    0.878676    0.517808    1.000000   \n",
      "max      0.769231    0.500000    1.650589    3.764706    1.994521    2.260000   \n",
      "\n",
      "              19          20  \n",
      "count  775.00000  775.000000  \n",
      "mean     0.16129    0.006828  \n",
      "std      0.44727    0.461905  \n",
      "min      0.00000   -0.666667  \n",
      "25%      0.00000   -0.520833  \n",
      "50%      0.00000    0.000000  \n",
      "75%      0.00000    0.479167  \n",
      "max      2.00000    1.145833  \n"
     ]
    }
   ],
   "source": [
    "# fit and transform X_train with original value in numerical features\n",
    "X_train_rob_scaled = preprocessor3.fit_transform(X_train)\n",
    "\n",
    "# transform X_test with original value in numerical features\n",
    "X_test_rob_scaled = preprocessor2.transform(X_test)\n",
    "\n",
    "# show the statistical summary\n",
    "print(f\"Basic statistical summary of predictors with robust scaled value: \\n\\n{pd.DataFrame(X_train_rob_scaled).loc[:, 13:20].describe()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try to do the modelling process of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the function for model evaluation \n",
    "def evaluate_model(true, predicted):\n",
    "    mae = mean_absolute_error(true, predicted)\n",
    "    mse = mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(true, predicted))\n",
    "    r2_square = r2_score(true, predicted)\n",
    "    return mae, rmse, r2_square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Value Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1284\n",
      "- Mean Absolute Error: 0.0912\n",
      "- R2 Score: 0.3884\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1411\n",
      "- Mean Absolute Error: 0.0991\n",
      "- R2 Score: 0.2358\n",
      "===================================\n",
      "\n",
      "\n",
      "Lasso\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1602\n",
      "- Mean Absolute Error: 0.1236\n",
      "- R2 Score: 0.0480\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1578\n",
      "- Mean Absolute Error: 0.1197\n",
      "- R2 Score: 0.0441\n",
      "===================================\n",
      "\n",
      "\n",
      "Ridge\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1288\n",
      "- Mean Absolute Error: 0.0918\n",
      "- R2 Score: 0.3851\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1411\n",
      "- Mean Absolute Error: 0.0998\n",
      "- R2 Score: 0.2352\n",
      "===================================\n",
      "\n",
      "\n",
      "SVR\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1614\n",
      "- Mean Absolute Error: 0.1241\n",
      "- R2 Score: 0.0346\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1595\n",
      "- Mean Absolute Error: 0.1201\n",
      "- R2 Score: 0.0230\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1272\n",
      "- Mean Absolute Error: 0.0899\n",
      "- R2 Score: 0.4001\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1603\n",
      "- Mean Absolute Error: 0.1193\n",
      "- R2 Score: 0.0133\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1675\n",
      "- Mean Absolute Error: 0.1009\n",
      "- R2 Score: -0.0774\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0466\n",
      "- Mean Absolute Error: 0.0289\n",
      "- R2 Score: 0.9196\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1281\n",
      "- Mean Absolute Error: 0.0810\n",
      "- R2 Score: 0.3702\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBRegressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0088\n",
      "- Mean Absolute Error: 0.0052\n",
      "- R2 Score: 0.9971\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1358\n",
      "- Mean Absolute Error: 0.0859\n",
      "- R2 Score: 0.2918\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1309\n",
      "- Mean Absolute Error: 0.0979\n",
      "- R2 Score: 0.3650\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1398\n",
      "- Mean Absolute Error: 0.1036\n",
      "- R2 Score: 0.2492\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create list of training algorithms\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Lasso\": Lasso(random_state=12),\n",
    "    \"Ridge\": Ridge(random_state=23),\n",
    "    \"SVR\": SVR(),\n",
    "    \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=34),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(random_state=45),\n",
    "    \"XGBRegressor\": XGBRegressor(random_state=56),\n",
    "    \"AdaBoost Regressor\": AdaBoostRegressor(random_state=67)\n",
    "}\n",
    "model_list = []\n",
    "r2_list =[]\n",
    "\n",
    "# Define the train and test datasets\n",
    "X_train=X_train_ori\n",
    "X_test=X_test_ori\n",
    "\n",
    "# display the model evaluation for each algorithm\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate Train and Test dataset\n",
    "    model_train_mae , model_train_rmse, model_train_r2 = evaluate_model(y_train, y_train_pred)\n",
    "\n",
    "    model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    \n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
    "    r2_list.append(model_test_r2)\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>R2_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>0.370244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.291778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoost Regressor</td>\n",
       "      <td>0.249229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.235821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.235193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.044109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVR</td>\n",
       "      <td>0.022994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Neighbors Regressor</td>\n",
       "      <td>0.013329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>-0.077407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model Name  R2_Score\n",
       "6  Random Forest Regressor  0.370244\n",
       "7             XGBRegressor  0.291778\n",
       "8       AdaBoost Regressor  0.249229\n",
       "0        Linear Regression  0.235821\n",
       "2                    Ridge  0.235193\n",
       "1                    Lasso  0.044109\n",
       "3                      SVR  0.022994\n",
       "4    K-Neighbors Regressor  0.013329\n",
       "5            Decision Tree -0.077407"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_original_predictors = pd.DataFrame(list(zip(model_list, r2_list)), columns=['Model Name', 'R2_Score']).sort_values(by=[\"R2_Score\"],ascending=False)\n",
    "result_original_predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Scaled Value Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1284\n",
      "- Mean Absolute Error: 0.0912\n",
      "- R2 Score: 0.3884\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1411\n",
      "- Mean Absolute Error: 0.0991\n",
      "- R2 Score: 0.2358\n",
      "===================================\n",
      "\n",
      "\n",
      "Lasso\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1642\n",
      "- Mean Absolute Error: 0.1284\n",
      "- R2 Score: 0.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1614\n",
      "- Mean Absolute Error: 0.1239\n",
      "- R2 Score: -0.0003\n",
      "===================================\n",
      "\n",
      "\n",
      "Ridge\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1284\n",
      "- Mean Absolute Error: 0.0911\n",
      "- R2 Score: 0.3884\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1410\n",
      "- Mean Absolute Error: 0.0990\n",
      "- R2 Score: 0.2366\n",
      "===================================\n",
      "\n",
      "\n",
      "SVR\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1089\n",
      "- Mean Absolute Error: 0.0800\n",
      "- R2 Score: 0.5605\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1390\n",
      "- Mean Absolute Error: 0.0986\n",
      "- R2 Score: 0.2586\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1122\n",
      "- Mean Absolute Error: 0.0744\n",
      "- R2 Score: 0.5332\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1392\n",
      "- Mean Absolute Error: 0.0913\n",
      "- R2 Score: 0.2562\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1675\n",
      "- Mean Absolute Error: 0.1008\n",
      "- R2 Score: -0.0769\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0466\n",
      "- Mean Absolute Error: 0.0289\n",
      "- R2 Score: 0.9196\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1281\n",
      "- Mean Absolute Error: 0.0811\n",
      "- R2 Score: 0.3696\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBRegressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0088\n",
      "- Mean Absolute Error: 0.0052\n",
      "- R2 Score: 0.9971\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1358\n",
      "- Mean Absolute Error: 0.0859\n",
      "- R2 Score: 0.2918\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1309\n",
      "- Mean Absolute Error: 0.0979\n",
      "- R2 Score: 0.3650\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1398\n",
      "- Mean Absolute Error: 0.1036\n",
      "- R2 Score: 0.2492\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create list of training algorithms\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Lasso\": Lasso(random_state=12),\n",
    "    \"Ridge\": Ridge(random_state=23),\n",
    "    \"SVR\": SVR(),\n",
    "    \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=34),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(random_state=45),\n",
    "    \"XGBRegressor\": XGBRegressor(random_state=56),\n",
    "    \"AdaBoost Regressor\": AdaBoostRegressor(random_state=67)\n",
    "}\n",
    "model_list = []\n",
    "r2_list =[]\n",
    "\n",
    "# Define the train and test datasets\n",
    "X_train=X_train_std_scaled\n",
    "X_test=X_test_std_scaled\n",
    "\n",
    "# display the model evaluation for each algorithm\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate Train and Test dataset\n",
    "    model_train_mae , model_train_rmse, model_train_r2 = evaluate_model(y_train, y_train_pred)\n",
    "\n",
    "    model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    \n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
    "    r2_list.append(model_test_r2)\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>R2_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>0.369636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.291778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVR</td>\n",
       "      <td>0.258565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Neighbors Regressor</td>\n",
       "      <td>0.256232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoost Regressor</td>\n",
       "      <td>0.249229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.236635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.235821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>-0.000305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>-0.076899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model Name  R2_Score\n",
       "6  Random Forest Regressor  0.369636\n",
       "7             XGBRegressor  0.291778\n",
       "3                      SVR  0.258565\n",
       "4    K-Neighbors Regressor  0.256232\n",
       "8       AdaBoost Regressor  0.249229\n",
       "2                    Ridge  0.236635\n",
       "0        Linear Regression  0.235821\n",
       "1                    Lasso -0.000305\n",
       "5            Decision Tree -0.076899"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_std_scaled_predictors = pd.DataFrame(list(zip(model_list, r2_list)), columns=['Model Name', 'R2_Score']).sort_values(by=[\"R2_Score\"],ascending=False)\n",
    "result_std_scaled_predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robust Scaled Value Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1284\n",
      "- Mean Absolute Error: 0.0912\n",
      "- R2 Score: 0.3884\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1411\n",
      "- Mean Absolute Error: 0.0991\n",
      "- R2 Score: 0.2358\n",
      "===================================\n",
      "\n",
      "\n",
      "Lasso\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1642\n",
      "- Mean Absolute Error: 0.1284\n",
      "- R2 Score: 0.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1614\n",
      "- Mean Absolute Error: 0.1239\n",
      "- R2 Score: -0.0003\n",
      "===================================\n",
      "\n",
      "\n",
      "Ridge\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1284\n",
      "- Mean Absolute Error: 0.0909\n",
      "- R2 Score: 0.3883\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1410\n",
      "- Mean Absolute Error: 0.0989\n",
      "- R2 Score: 0.2363\n",
      "===================================\n",
      "\n",
      "\n",
      "SVR\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1105\n",
      "- Mean Absolute Error: 0.0824\n",
      "- R2 Score: 0.5475\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1442\n",
      "- Mean Absolute Error: 0.1051\n",
      "- R2 Score: 0.2021\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1178\n",
      "- Mean Absolute Error: 0.0807\n",
      "- R2 Score: 0.4853\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1511\n",
      "- Mean Absolute Error: 0.1012\n",
      "- R2 Score: 0.1231\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1667\n",
      "- Mean Absolute Error: 0.1007\n",
      "- R2 Score: -0.0670\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0465\n",
      "- Mean Absolute Error: 0.0289\n",
      "- R2 Score: 0.9197\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1278\n",
      "- Mean Absolute Error: 0.0809\n",
      "- R2 Score: 0.3727\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBRegressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0088\n",
      "- Mean Absolute Error: 0.0052\n",
      "- R2 Score: 0.9971\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1358\n",
      "- Mean Absolute Error: 0.0859\n",
      "- R2 Score: 0.2918\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1309\n",
      "- Mean Absolute Error: 0.0979\n",
      "- R2 Score: 0.3650\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.1398\n",
      "- Mean Absolute Error: 0.1036\n",
      "- R2 Score: 0.2492\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create list of training algorithms\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Lasso\": Lasso(random_state=12),\n",
    "    \"Ridge\": Ridge(random_state=23),\n",
    "    \"SVR\": SVR(),\n",
    "    \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=34),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(random_state=45),\n",
    "    \"XGBRegressor\": XGBRegressor(random_state=56),\n",
    "    \"AdaBoost Regressor\": AdaBoostRegressor(random_state=67)\n",
    "}\n",
    "model_list = []\n",
    "r2_list =[]\n",
    "\n",
    "# Define the train and test datasets\n",
    "X_train=X_train_rob_scaled\n",
    "X_test=X_test_rob_scaled\n",
    "\n",
    "# display the model evaluation for each algorithm\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate Train and Test dataset\n",
    "    model_train_mae , model_train_rmse, model_train_r2 = evaluate_model(y_train, y_train_pred)\n",
    "\n",
    "    model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    \n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
    "    r2_list.append(model_test_r2)\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>R2_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>0.372725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.291778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoost Regressor</td>\n",
       "      <td>0.249229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.236348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.235821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVR</td>\n",
       "      <td>0.202075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Neighbors Regressor</td>\n",
       "      <td>0.123141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>-0.000305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>-0.066993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model Name  R2_Score\n",
       "6  Random Forest Regressor  0.372725\n",
       "7             XGBRegressor  0.291778\n",
       "8       AdaBoost Regressor  0.249229\n",
       "2                    Ridge  0.236348\n",
       "0        Linear Regression  0.235821\n",
       "3                      SVR  0.202075\n",
       "4    K-Neighbors Regressor  0.123141\n",
       "1                    Lasso -0.000305\n",
       "5            Decision Tree -0.066993"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_rob_scaled_predictors = pd.DataFrame(list(zip(model_list, r2_list)), columns=['Model Name', 'R2_Score']).sort_values(by=[\"R2_Score\"],ascending=False)\n",
    "result_rob_scaled_predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best r-squared value is resulted from the predictors that transformed using standard scaled method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model is: \n",
      "\n",
      "                Model Name  R2_Score\n",
      "6  Random Forest Regressor  0.372725\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best model is: \\n\\n{result_rob_scaled_predictors.head(1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 37.27\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestRegressor(random_state=45)\n",
    "rf_model = rf_model.fit(X_train_rob_scaled, y_train)\n",
    "y_pred = rf_model.predict(X_test_rob_scaled)\n",
    "score = r2_score(y_test, y_pred)*100\n",
    "print(\"Accuracy of the model is %.2f\" %score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning on Random Forest Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to improve the model accuracy value.\n",
    "\n",
    "With the grid search and randomized search cross-validation methods on the Random Forest Regressor defined parameters grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# Define the parameter grid for RandomForestRegressor\n",
    "param_grid = {\n",
    "    'criterion': [\"squared_error\", \"absolute_error\", \"friedman_mse\", \"poisson\"],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "model = RandomForestRegressor(random_state=45)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/er_bim/productivity-prediction/venv/lib/python3.10/site-packages/numpy/_core/getlimits.py:545: UserWarning: Signature b'\\x00\\xd0\\xcc\\xcc\\xcc\\xcc\\xcc\\xcc\\xfb\\xbf\\x00\\x00\\x00\\x00\\x00\\x00' for <class 'numpy.longdouble'> does not match any known type: falling back to type probe function.\n",
      "This warnings indicates broken support for the dtype!\n",
      "  machar = _get_machar(dtype)\n",
      "/home/er_bim/productivity-prediction/venv/lib/python3.10/site-packages/numpy/_core/getlimits.py:545: UserWarning: Signature b'\\x00\\xd0\\xcc\\xcc\\xcc\\xcc\\xcc\\xcc\\xfb\\xbf\\x00\\x00\\x00\\x00\\x00\\x00' for <class 'numpy.longdouble'> does not match any known type: falling back to type probe function.\n",
      "This warnings indicates broken support for the dtype!\n",
      "  machar = _get_machar(dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'criterion': 'friedman_mse', 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "Best Model Test Set R2: 0.3848\n"
     ]
    }
   ],
   "source": [
    "# Set up the GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, n_jobs=-1, scoring='r2')\n",
    "\n",
    "# Define the train and test datasets\n",
    "X_train=X_train_rob_scaled\n",
    "X_test=X_test_rob_scaled\n",
    "\n",
    "# Fit the GridSearchCV to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(f\"Best parameters found: {best_params}\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "r2_value_gridsearch = r2_score(y_test, y_test_pred)\n",
    "print(f\"Best Model Test Set R2: {r2_value_gridsearch:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomized Search Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'n_estimators': 300, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_depth': 20, 'criterion': 'friedman_mse'}\n",
      "Best Model Test Set R2: 0.3849\n"
     ]
    }
   ],
   "source": [
    "# Set up the RandomizedSearchCV\n",
    "rand_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter = 50, cv = 5, n_jobs = -1, scoring='r2', random_state=99)\n",
    "\n",
    "# Define the train and test datasets\n",
    "X_train=X_train_rob_scaled\n",
    "X_test=X_test_rob_scaled\n",
    "\n",
    "# Fit the GridSearchCV to the data\n",
    "rand_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best model\n",
    "best_params = rand_search.best_params_\n",
    "best_model = rand_search.best_estimator_\n",
    "\n",
    "print(f\"Best parameters found: {best_params}\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "best_r2_randomizedsearch = r2_score(y_test, y_test_pred)\n",
    "print(f\"Best Model Test Set R2: {best_r2_randomizedsearch:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameter tuning experiments with randomized search cross-validation slightly improve the model performance, so we will apply its parameters to the model with the predictors transformed by standard scale method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The acccuracy of the model is 38.4915%\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestRegressor(n_estimators= 300, \n",
    "                                 min_samples_split= 10, \n",
    "                                 min_samples_leaf= 1, \n",
    "                                 max_depth= 20, \n",
    "                                 criterion= 'friedman_mse', \n",
    "                                 random_state=45\n",
    "                                 )\n",
    "rf_model = rf_model.fit(X_train_rob_scaled, y_train)\n",
    "y_pred = rf_model.predict(X_test_rob_scaled)\n",
    "score = r2_score(y_test, y_pred)*100\n",
    "print(f\"The acccuracy of the model is {score:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters used by model:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'criterion': 'friedman_mse',\n",
      " 'max_depth': 20,\n",
      " 'max_features': 1.0,\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 10,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'monotonic_cst': None,\n",
      " 'n_estimators': 300,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 45,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# check the parameters used by the model\n",
    "from pprint import pprint\n",
    "print('Parameters used by model:\\n')\n",
    "pprint(rf_model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Value</th>\n",
       "      <th>Predicted Value</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>0.840889</td>\n",
       "      <td>0.834308</td>\n",
       "      <td>0.006581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>0.902500</td>\n",
       "      <td>0.854726</td>\n",
       "      <td>0.047774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.699965</td>\n",
       "      <td>0.700503</td>\n",
       "      <td>-0.000538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>0.618361</td>\n",
       "      <td>0.820672</td>\n",
       "      <td>-0.202311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>0.750797</td>\n",
       "      <td>0.660350</td>\n",
       "      <td>0.090447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>0.404145</td>\n",
       "      <td>0.502142</td>\n",
       "      <td>-0.097997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>0.354444</td>\n",
       "      <td>0.622451</td>\n",
       "      <td>-0.268007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>0.858144</td>\n",
       "      <td>0.853152</td>\n",
       "      <td>0.004992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>0.672141</td>\n",
       "      <td>0.715473</td>\n",
       "      <td>-0.043332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>0.800359</td>\n",
       "      <td>0.800835</td>\n",
       "      <td>-0.000476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual Value  Predicted Value  Difference\n",
       "615      0.840889         0.834308    0.006581\n",
       "734      0.902500         0.854726    0.047774\n",
       "56       0.699965         0.700503   -0.000538\n",
       "666      0.618361         0.820672   -0.202311\n",
       "649      0.750797         0.660350    0.090447\n",
       "..            ...              ...         ...\n",
       "989      0.404145         0.502142   -0.097997\n",
       "968      0.354444         0.622451   -0.268007\n",
       "254      0.858144         0.853152    0.004992\n",
       "803      0.672141         0.715473   -0.043332\n",
       "312      0.800359         0.800835   -0.000476\n",
       "\n",
       "[333 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df=pd.DataFrame({'Actual Value':y_test,'Predicted Value':y_pred,'Difference':y_test-y_pred})\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.regplot(x=y_test,y=y_pred,ci=None,color ='red');\n",
    "plt.xlabel('Actual');\n",
    "plt.ylabel('Predicted');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
